{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "young-potter",
   "metadata": {},
   "source": [
    "## Import all Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "satellite-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS Rekognition to get bbox\n",
    "import numpy as np\n",
    "import boto3\n",
    "from PIL import Image, ImageDraw, ExifTags, ImageColor, ImageFont\n",
    "from matplotlib import pyplot as plt\n",
    "from utils.rekognition import determine_color, draw_animal_count\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "from utils.config import *\n",
    "from utils.fix_annotation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "employed-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process whole image.py to get key points\n",
    "import mmcv\n",
    "from mmcv.parallel import collate, scatter\n",
    "from mmcv.runner import load_checkpoint\n",
    "import torch as tr\n",
    "#from torchvision import transforms\n",
    "from mmpose.apis import (inference, inference_top_down_pose_model, init_pose_model,\n",
    "                         vis_pose_result)\n",
    "from mmpose.models import build_posenet\n",
    "from mmpose.datasets.pipelines import Compose\n",
    "\n",
    "FNT = ImageFont.truetype('/usr/share/fonts/default/Type1/n019004l.pfb', 21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-marble",
   "metadata": {},
   "source": [
    "## Get Bounding Boxes from Video Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "union-lloyd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadImage:\n",
    "    \"\"\"A simple pipeline to load image.\"\"\"\n",
    "\n",
    "    def __init__(self, color_type='color', channel_order='rgb'):\n",
    "        self.color_type = color_type\n",
    "        self.channel_order = channel_order\n",
    "\n",
    "    def __call__(self, results):\n",
    "        \"\"\"Call function to load images into results.\n",
    "        Args:\n",
    "            results (dict): A result dict contains the img_or_path.\n",
    "        Returns:\n",
    "            dict: ``results`` will be returned containing loaded image.\n",
    "        \"\"\"\n",
    "        if isinstance(results['img_or_path'], str):\n",
    "            results['image_file'] = results['img_or_path']\n",
    "            img = mmcv.imread(results['img_or_path'], self.color_type,\n",
    "                              self.channel_order)\n",
    "        elif isinstance(results['img_or_path'], np.ndarray):\n",
    "            results['image_file'] = ''\n",
    "            if self.color_type == 'color' and self.channel_order == 'rgb':\n",
    "                img = cv2.cvtColor(results['img_or_path'], cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            raise TypeError('\"img_or_path\" must be a numpy array or a str or '\n",
    "                            'a pathlib.Path object')\n",
    "        results['img'] = img\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "important-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_pose_model(config, checkpoint=None, device='cuda:0'):\n",
    "    \"\"\"Initialize a pose model from config file.\n",
    "    Args:\n",
    "        config (str or :obj:`mmcv.Config`): Config file path or the config\n",
    "            object.\n",
    "        checkpoint (str, optional): Checkpoint path. If left as None, the model\n",
    "            will not load any weights.\n",
    "    Returns:\n",
    "        nn.Module: The constructed detector.\n",
    "    \"\"\"\n",
    "    if isinstance(config, str):\n",
    "        config = mmcv.Config.fromfile(config)\n",
    "    elif not isinstance(config, mmcv.Config):\n",
    "        raise TypeError('config must be a filename or Config object, '\n",
    "                        f'but got {type(config)}')\n",
    "    config.model.pretrained = None\n",
    "    model = build_posenet(config.model)\n",
    "    if checkpoint is not None:\n",
    "        # load model checkpoint\n",
    "        load_checkpoint(model, checkpoint, map_location=device)\n",
    "    # save the config in the model for convenience\n",
    "    model.cfg = config\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "administrative-philip",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _box2cs(cfg, box):\n",
    "    \"\"\"This encodes bbox(x,y,w,h) into (center, scale)\n",
    "    Args:\n",
    "        x, y, w, h\n",
    "    Returns:\n",
    "        tuple: A tuple containing center and scale.\n",
    "        - np.ndarray[float32](2,): Center of the bbox (x, y).\n",
    "        - np.ndarray[float32](2,): Scale of the bbox w & h.\n",
    "    \"\"\"\n",
    "\n",
    "    x, y, w, h = box[:4]\n",
    "    input_size = cfg.data_cfg['image_size']\n",
    "    aspect_ratio = input_size[0] / input_size[1]\n",
    "    center = np.array([x + w * 0.5, y + h * 0.5], dtype=np.float32)\n",
    "\n",
    "    if w > aspect_ratio * h:\n",
    "        h = w * 1.0 / aspect_ratio\n",
    "    elif w < aspect_ratio * h:\n",
    "        w = h * aspect_ratio\n",
    "\n",
    "    # pixel std is 200.0\n",
    "    scale = np.array([w / 200.0, h / 200.0], dtype=np.float32)\n",
    "\n",
    "    scale = scale * 1.25\n",
    "\n",
    "    return center, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sized-hebrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_model(model, dataset, person_results, img_or_path):\n",
    "    bboxes = np.array([box['bbox'] for box in person_results])\n",
    "    cfg = model.cfg\n",
    "    flip_pairs = None\n",
    "    device = next(model.parameters()).device\n",
    "    channel_order = cfg.test_pipeline[0].get('channel_order', 'rgb')\n",
    "    test_pipeline = [LoadImage(channel_order=channel_order)] + cfg.test_pipeline[1:]\n",
    "    test_pipeline = Compose(test_pipeline)\n",
    "    if dataset == 'AnimalHorse10Dataset':\n",
    "        flip_pairs = []\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "    batch_data = []\n",
    "    for bbox in bboxes:\n",
    "        center, scale = _box2cs(cfg, bbox)\n",
    "        # prepare data\n",
    "        data = {\n",
    "            'img_or_path':\n",
    "            img_or_path,\n",
    "            'center':\n",
    "            center,\n",
    "            'scale':\n",
    "            scale,\n",
    "            'bbox_score':\n",
    "            bbox[4] if len(bbox) == 5 else 1,\n",
    "            'bbox_id':\n",
    "            0,  # need to be assigned if batch_size > 1\n",
    "            'dataset':\n",
    "            dataset,\n",
    "            'joints_3d':\n",
    "            np.zeros((cfg.data_cfg.num_joints, 3), dtype=np.float32),\n",
    "            'joints_3d_visible':\n",
    "            np.zeros((cfg.data_cfg.num_joints, 3), dtype=np.float32),\n",
    "            'rotation':\n",
    "            0,\n",
    "            'ann_info': {\n",
    "                'image_size': np.array(cfg.data_cfg['image_size']),\n",
    "                'num_joints': cfg.data_cfg['num_joints'],\n",
    "                'flip_pairs': flip_pairs\n",
    "            }\n",
    "        }\n",
    "        data = test_pipeline(data)\n",
    "        batch_data.append(data)\n",
    "    batch_data = collate(batch_data, samples_per_gpu=1)\n",
    "    if next(model.parameters()).is_cuda:\n",
    "        # scatter not work so just move image to cuda device\n",
    "        batch_data['img'] = batch_data['img'].to(device)\n",
    "    # get all img_metas of each bounding box\n",
    "    batch_data['img_metas'] = [\n",
    "        img_metas[0] for img_metas in batch_data['img_metas'].data\n",
    "    ]\n",
    "\n",
    "    with tr.no_grad():\n",
    "        result = model(\n",
    "            img=batch_data['img'],\n",
    "            #img = torch_data,\n",
    "            img_metas=batch_data['img_metas'],\n",
    "            return_loss=False,\n",
    "            return_heatmap=False)\n",
    "    return result['preds'], result['output_heatmap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "brutal-database",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Use load_from_local loader\n",
      "Use load_from_local loader\n",
      "Use load_from_local loader\n",
      "Use load_from_local loader\n",
      "Use load_from_local loader\n"
     ]
    }
   ],
   "source": [
    "device = tr.device(\"cuda:0\" if tr.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model_head = init_pose_model(config='../my_configs/cattle/resnet_50_10/head_black.py', checkpoint='../train_result/cattle/resnet_50_10/head_black/best.pth', device = device)\n",
    "model_spine = init_pose_model(config='../my_configs/cattle/resnet_50_5/spine_black.py', checkpoint='../train_result/cattle/resnet_50_5/spine_black/best.pth', device = device)\n",
    "model_tail = init_pose_model(config='../my_configs/cattle/resnet_50_5/tail_black.py', checkpoint='../train_result/cattle/resnet_50_5/tail_black/best.pth', device = device)\n",
    "model_leg_front = init_pose_model(config='../my_configs/cattle/resnet_50_10/leg_front_black.py', checkpoint='../train_result/cattle/resnet_50_10/leg_front_black/best.pth', device = device)\n",
    "model_leg_back = init_pose_model(config='../my_configs/cattle/resnet_50_5/leg_back_black.py', checkpoint='../train_result/cattle/resnet_50_5/leg_back_black/best.pth', device = device)\n",
    "\n",
    "dataset_head = model_head.cfg.data['test']['type']\n",
    "dataset_spine = model_spine.cfg.data['test']['type']\n",
    "dataset_tail = model_tail.cfg.data['test']['type']\n",
    "dataset_leg_front = model_leg_front.cfg.data['test']['type']\n",
    "dataset_leg_back = model_leg_back.cfg.data['test']['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "printable-geology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kp_color(label):\n",
    "    # BGR\n",
    "    color = (0, 0, 255)\n",
    "    if label == 'Head':\n",
    "        color = ['#EC51F8', '#74F54B', \n",
    "                 '#EC51F8', '#74F54B',\n",
    "                 '#4394F9', '#F49736',\n",
    "                 '#F49736', '#FFFB56',\n",
    "                 '#FFFB56', '#4394F9',\n",
    "                 '#07178D']\n",
    "    elif label == 'Spine':\n",
    "          color = ['#4394F9', '#4394F9', '#4394F9',\n",
    "                  '#4394F9', '#4394F9', '#4394F9', \n",
    "                  '#4394F9', '#4394F9', '#24518D']\n",
    "    elif label == 'Tail':\n",
    "        color = ['#EC51F8', '#EC51F8',\n",
    "                '#EC51F8', '#EC51F8',\n",
    "                '#EC51F8', '#892B8E']\n",
    "    elif label == 'Leg_front':\n",
    "        color = ['#F49736', '#F49736',\n",
    "                '#F49736', '#F49736',\n",
    "                '#F49736', '#F49736',\n",
    "                '#F49736', '#F49736',\n",
    "                '#F49736', '#8C551E']\n",
    "    elif label == 'Leg_back':\n",
    "        color = ['#74F54B', '#74F54B',\n",
    "                '#74F54B', '#74F54B',\n",
    "                '#74F54B', '#74F54B',\n",
    "                '#74F54B', '#74F54B',\n",
    "                '#74F54B', '#3F8D28',]\n",
    "    return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "grand-impossible",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skeleton(label):\n",
    "    skeleton_list = []\n",
    "    if label == 'Head':\n",
    "        skeleton_list = [[4, 0], [4, 2], [0, 2], [1, 3], \n",
    "                        [5, 6], [7, 8], [0, 1], [1, 5],\n",
    "                        [5, 7], [7, 9], [2, 3], [3, 6],\n",
    "                        [6, 8], [8, 9], [4, 9]]\n",
    "    elif label == 'Spine':\n",
    "        skeleton_list = [[0, 1], [1, 2], [2, 3], [3, 4],\n",
    "                        [4, 5], [5, 6], [6, 7]]\n",
    "    elif label == 'Tail':\n",
    "        skeleton_list = [[0, 1], [1, 2], [2, 3], [3, 4]]\n",
    "    elif label == 'Leg_front':\n",
    "        skeleton_list = [[0, 1], [1, 2], [2, 3], [3, 4],\n",
    "                        [4, 5], [5, 6], [6, 7], [7, 8]]\n",
    "    elif label == 'Leg_back':\n",
    "        skeleton_list = [[0, 1], [1, 2], [2, 3], [3, 4],\n",
    "                        [4, 5], [5, 6], [6, 7], [7, 8]]\n",
    "    return skeleton_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "underlying-paper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_bgr(color):\n",
    "    color = list(color)\n",
    "    temp_r = color[0]\n",
    "    color[0] = color[2]\n",
    "    color[2] = temp_r\n",
    "    return tuple(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "comparative-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAngle(a, b, c):\n",
    "    ang = math.degrees(math.atan2(\n",
    "        c[1]-b[1], c[0]-b[0]) - math.atan2(a[1]-b[1], a[0]-b[0]))\n",
    "\n",
    "    if ang < 0:\n",
    "        ang + 360\n",
    "    elif ang > 90:\n",
    "        #print('**The original angle was :', ang)\n",
    "        360 - ang\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return abs(ang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "minimal-holmes",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_pose(points, draw, label, temp_bbox, size, scale_rate):\n",
    "    #print(temp_bbox, size, scale_rate, label)\n",
    "    points = points[0]\n",
    "#     if label == 'Leg_front' or label == 'Leg_back':\n",
    "#         print('Leg_front')\n",
    "#         print(points)\n",
    "    CS_THR = 0.4\n",
    "    # keypoints\n",
    "    kp_color = get_kp_color(label)\n",
    "    # connect line\n",
    "    skeleton_list = get_skeleton(label)\n",
    "    for ske in skeleton_list:\n",
    "        fir_pt_x, fir_pt_y, fir_pt_p = points[ske[0]]\n",
    "        sec_pt_x, sec_pt_y, sec_pt_p = points[ske[1]]\n",
    "        if fir_pt_p > CS_THR and sec_pt_p > CS_THR:\n",
    "#             shape = [(fir_pt_x, fir_pt_y), (sec_pt_x, sec_pt_y)]\n",
    "#             print('before shape')\n",
    "#             print(shape)\n",
    "            # draw line\n",
    "            if fir_pt_x < size[0] and fir_pt_y < size[1] and sec_pt_x < size[0] and sec_pt_y < size[1]:\n",
    "#                 shape = [(fir_pt_x, fir_pt_y), (sec_pt_x, sec_pt_y)]\n",
    "#                 print('shape')\n",
    "#                 print(shape)\n",
    "                fir_pt_x = temp_bbox[0] + fir_pt_x / scale_rate[0]\n",
    "                fir_pt_y = temp_bbox[1] + fir_pt_y / scale_rate[1]\n",
    "                sec_pt_x = temp_bbox[0] + sec_pt_x / scale_rate[0]\n",
    "                sec_pt_y = temp_bbox[1] + sec_pt_y / scale_rate[1]\n",
    "                shape = [(fir_pt_x, fir_pt_y), (sec_pt_x, sec_pt_y)]\n",
    "#                 print('scaled shape')\n",
    "#                 print(shape)\n",
    "                draw.line(shape, fill=kp_color[-1], width=8)\n",
    "    \n",
    "    for i, point in enumerate(points):\n",
    "        x, y, p = point\n",
    "        if p > CS_THR and x < size[0] and y < size[1]:\n",
    "            # draw keypoints\n",
    "            x = int(temp_bbox[0] + x / scale_rate[0])\n",
    "            y = int(temp_bbox[1] + y / scale_rate[1])\n",
    "#             x = int(x)\n",
    "#             y = int(y)\n",
    "            draw.ellipse([(x-11, y-11), (x+11, y+11)], fill=kp_color[-1], outline=None)\n",
    "            draw.ellipse([(x-6, y-6), (x+6, y+6)], fill=kp_color[i], outline=None)\n",
    "            #draw.text((x-40, y-40), '{}%'.format(int(p*100)), font=FNT, fill=(255, 255, 255))\n",
    "            #draw.text((x-40, y-40), str(i), font=FNT, fill=(255, 255, 255))\n",
    "            # draw angle on legs\n",
    "            if (label == 'Leg_front' or label == 'Leg_back') and i > 0 and i < 8 and points[i-1][2] > CS_THR and points[i+1][2] > CS_THR:\n",
    "                #print(label)\n",
    "                #print(points[i+1], points[i], points[i-1])\n",
    "                angle = getAngle(points[i+1], points[i], points[i-1])\n",
    "                # pieslice bbox\n",
    "                delta_x = (points[i+1][0]-points[i][0])\n",
    "                delta_y = (points[i+1][1]-points[i][1])\n",
    "                if i >= 5:\n",
    "                    delta_x = (points[i-1][0]-points[i][0])\n",
    "                    delta_y = (points[i-1][1]-points[i][1])\n",
    "                start_angle = math.degrees(math.atan2(delta_y, delta_x))\n",
    "                end_angle = round(angle)+start_angle\n",
    "#                 print('y', points[i+1][1], points[i][1], (points[i+1][1]-points[i][1]))\n",
    "#                 print('x', points[i+1][0], points[i][0], (points[i+1][0]-points[i][0]))\n",
    "#                 print('angle', start_angle)\n",
    "#                 print(start_angle, end_angle)\n",
    "                shift_x = 8\n",
    "                shift_y = 0\n",
    "                # center keypoint\n",
    "                if i == 4:\n",
    "                    shift_x = 0\n",
    "                    shift_y = 15\n",
    "                    if points[5][0] < points[3][0]:\n",
    "                        #print('before angle', start_angle, end_angle)\n",
    "                        shift_x = 5\n",
    "                        temp_start_angle = start_angle\n",
    "                        start_angle = end_angle - round(angle) * 2\n",
    "                        end_angle = temp_start_angle\n",
    "                # last keypoints\n",
    "                if i == 1 or i == 7:\n",
    "                    shift_x = 10\n",
    "                    shift_y = 0\n",
    "                shape = [(x-55+shift_x, y-55+shift_y), (x+55+shift_x, y+55+shift_y)]\n",
    "                draw.pieslice(shape, start=start_angle, end=end_angle, fill='#FF9300'+f'{round(0.5*255):0>2X}', outline='#FF9300', width=3)\n",
    "                draw.text((x+10+shift_x, y-13), \"{:.0f}\".format(angle)+u'\\N{DEGREE SIGN}', font=FNT, fill=(255,255,255))\n",
    "    \n",
    "    return draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "thick-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_bbox(left, top, width, height, extend_rate):\n",
    "    temp_left = left - (width * extend_rate / 2)\n",
    "    temp_top = top - (height * extend_rate / 2)\n",
    "    temp_width = width + (width * extend_rate / 2)\n",
    "    temp_height = height + (height * extend_rate / 2)\n",
    "    return temp_left, temp_top, temp_width, temp_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "still-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color(name):\n",
    "    if name == 'cow' or name == 'animal':\n",
    "        color = '#FF9300'\n",
    "    elif name == 'head' or name == \"head left\" or name == \"head right\":\n",
    "        color = '#0096FF'\n",
    "    elif name == 'tag':\n",
    "        color = '#00FFFF'\n",
    "    elif name == 'knee':\n",
    "        color = '#FFFB00'\n",
    "    elif name == 'hoof':\n",
    "        color = '#00F900'\n",
    "    elif name == 'tail':\n",
    "        color = '#FF40FF'\n",
    "    elif name == 'side left' or name == 'side right':\n",
    "        color = '#FF2600'\n",
    "    elif name == 'udder':\n",
    "        color = '#9437FF'\n",
    "    elif name == 'teat':\n",
    "        color = '#FF2F92'\n",
    "    else:\n",
    "        color = '#000000'\n",
    "    return color\n",
    "\n",
    "def get_opacity(name):\n",
    "    if name == 'cow' or name == 'animal':\n",
    "        opacity = 0.3\n",
    "    elif name == 'tag':\n",
    "        opacity = 0.3\n",
    "    elif name == 'head' or name == \"head Left\" or name == \"head Right\":\n",
    "        opacity = 0.45\n",
    "    elif name == 'knee':\n",
    "        opacity = 0.3\n",
    "    elif name == 'hoof':\n",
    "        opacity = 0.35\n",
    "    elif name == 'tail':\n",
    "        opacity = 0.3\n",
    "    elif name == 'side left' or name == 'side right':\n",
    "        opacity = 0.3\n",
    "    elif name == 'udder':\n",
    "        opacity = 0.35\n",
    "    elif name == 'teat':\n",
    "        opacity = 0.3\n",
    "    else:\n",
    "        opacity = 0.0\n",
    "\n",
    "    return opacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "celtic-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confidence_cut_off(name):\n",
    "    if name == 'cow':\n",
    "        confidence = 79.4\n",
    "    elif name == 'tag':\n",
    "        confidence = 86.9\n",
    "    elif name == 'head':\n",
    "        confidence = 92.5\n",
    "    elif name == 'knee':\n",
    "        confidence = 78.0\n",
    "    elif name == 'hoof':\n",
    "        confidence = 92.9\n",
    "    elif name == 'tail':\n",
    "        confidence = 73.5\n",
    "    elif name == 'udder':\n",
    "        confidence = 35.0\n",
    "    elif name == 'teat':\n",
    "        confidence = 73.0\n",
    "    elif name == 'animal':\n",
    "        confidence = 80.0\n",
    "    else:\n",
    "        confidence = 80.0\n",
    "\n",
    "    return confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "interior-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(image, bbox, label):\n",
    "    temp_bbox = [bbox[0], bbox[1], bbox[0]+bbox[2], bbox[1]+bbox[3]]\n",
    "    \n",
    "    ori_image = Image.fromarray(image, 'RGB')    \n",
    "    cropped_image = ori_image.copy().crop(temp_bbox)\n",
    "#     if label == \"tail\" and cropped_image.size[1] == 426:\n",
    "#         print(cropped_image.size)\n",
    "#         cropped_image.save('./'+label+'_crop_image.jpg')\n",
    "    # rescale images and annotations\n",
    "    size_x = 256\n",
    "    size_y = 256\n",
    "    \n",
    "    # Image.ANTIALIAS scale the cropped image (head)\n",
    "    ori_crop_size = cropped_image.size\n",
    "    cropped_image.thumbnail((size_x, size_y), Image.ANTIALIAS)\n",
    "#     if cropped_image.size[0] == 0 and cropped_image.size[1] == 0:\n",
    "#         print(ori_image.size)\n",
    "#         print(temp_bbox)\n",
    "#         print(cropped_image.size)\n",
    "    # scale keypoints\n",
    "    new_image = Image.new('RGB', (size_x, size_y), color = 'black')\n",
    "    new_image.paste(cropped_image)\n",
    "    cropped_image_size = cropped_image.size\n",
    "    scale_rate = (cropped_image_size[0]/ori_crop_size[0], cropped_image_size[1]/ori_crop_size[1])\n",
    "#     if label == \"tail\" and ori_crop_size[1] == 426:\n",
    "#         cropped_image_size = cropped_image.size\n",
    "#         print(cropped_image_size)\n",
    "#         print(ori_crop_size)\n",
    "#         print(cropped_image_size[0]/ori_crop_size[0], cropped_image_size[1]/ori_crop_size[1])\n",
    "#         new_image.save('./'+label+'_back_image.jpg')\n",
    "    new_image = np.array(new_image)\n",
    "#     print(cropped_image.size)\n",
    "#     print(temp_bbox)\n",
    "    return new_image, temp_bbox, cropped_image_size, scale_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "trained-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail_count = 0\n",
    "#draw response\n",
    "def draw_response(image, response, animal_target, draw_boundary=True, fill=True, draw_btn=True):\n",
    "    global tail_count\n",
    "    tail_check = False\n",
    "    temp_image = image.copy()\n",
    "    b, g, r = image.split()\n",
    "    image = Image.merge(\"RGB\", (r, g, b))\n",
    "    # original image size\n",
    "    draw = ImageDraw.Draw(image, mode='RGBA')\n",
    "    # bbox\n",
    "    for customLabel in response['CustomLabels']:\n",
    "        if 'Geometry' in customLabel:\n",
    "            box = customLabel['Geometry']['BoundingBox']\n",
    "            left, top, width, height = extend_bbox(box['Left'], box['Top'], box['Width'], box['Height'], 0)\n",
    "            label = customLabel['Name'].lower()\n",
    "            if label == 'Udder':\n",
    "                print('Udder')\n",
    "            elif label == 'Teat':\n",
    "                print('Teat')\n",
    "            conf_cut = get_confidence_cut_off(label)\n",
    "            # skip current label\n",
    "            if customLabel['Confidence'] < conf_cut:\n",
    "                continue\n",
    "            #draw bbox\n",
    "            color = get_color(label)\n",
    "            opacity = round(get_opacity(label) * 255)\n",
    "            if draw_boundary and fill:  \n",
    "                draw.rectangle(xy=[(left, top), (left+width, top+height)], outline=color, fill=color+f'{opacity:0>2X}', width=3)\n",
    "            elif fill:\n",
    "                draw.rectangle(xy=[(left, top), (left+width, top+height)], outline=None, fill=color+f'{opacity:0>2X}', width=3)\n",
    "            elif draw_boundary:\n",
    "                draw.rectangle(xy=[(left, top), (left+width, top+height)], outline=color, fill=None, width=3)\n",
    "            if draw_btn:\n",
    "                text_width, text_height = FNT.getsize(label)\n",
    "                draw.rectangle(xy=[(left, top), (left+text_width, top+text_height)], outline=None, fill=color, width=3)\n",
    "                draw.text((left, top), label, fill='#000000', font=FNT)\n",
    "    #keypoints\n",
    "    for customLabel in response['CustomLabels']:\n",
    "        if 'Geometry' in customLabel:\n",
    "            box = customLabel['Geometry']['BoundingBox']\n",
    "            left, top, width, height = extend_bbox(box['Left'], box['Top'], box['Width'], box['Height'], 0)\n",
    "            label = customLabel['Name'].lower()\n",
    "            #lower case for comparison\n",
    "            conf_cut = get_confidence_cut_off(label)\n",
    "            # skip current label\n",
    "            if customLabel['Confidence'] < conf_cut:\n",
    "                continue\n",
    "        #***** Keypoints\n",
    "            if label == 'head':\n",
    "                extend_rate = 0.1\n",
    "                np_image = np.array(temp_image)                \n",
    "                head_bbox = list(extend_bbox(box['Left'], box['Top'], box['Width'], box['Height'], extend_rate))\n",
    "                #cropped_image = np_image\n",
    "                cropped_image, temp_bbox, size, boundary = crop_image(np_image, head_bbox, label)\n",
    "                head_result = []\n",
    "                head_result.append({'bbox': [0, 0, 255, 255]})\n",
    "                preds, _ = process_model(model_head, dataset_head, head_result, cropped_image)\n",
    "                draw = vis_pose(preds, draw, 'Head', temp_bbox, size, boundary)\n",
    "            elif label == 'cow' or label == 'animal':\n",
    "                extend_rate = 0.05\n",
    "                np_image = np.array(temp_image)\n",
    "                cow_bbox = list(extend_bbox(box['Left'], box['Top'], box['Width'], box['Height'], extend_rate))\n",
    "                #cropped_image = np_image\n",
    "                cropped_image, temp_bbox, size, boundary = crop_image(np_image, cow_bbox, label)\n",
    "                cow_result = []\n",
    "                cow_result.append({'bbox': [0, 0, 255, 255]})\n",
    "                # spine\n",
    "                #print(label, 'Spine')\n",
    "                preds, _ = process_model(model_spine, dataset_spine, cow_result, cropped_image)\n",
    "                draw = vis_pose(preds, draw, 'Spine', temp_bbox, size, boundary)\n",
    "                # leg back\n",
    "                preds, _ = process_model(model_leg_back, dataset_leg_back, cow_result, cropped_image)\n",
    "                draw = vis_pose(preds, draw, 'Leg_back', temp_bbox, size, boundary)\n",
    "                # leg front\n",
    "                extend_rate = 0.1\n",
    "                np_image = np.array(temp_image)\n",
    "                cow_bbox = list(extend_bbox(box['Left'], box['Top'], box['Width'], box['Height'], extend_rate))\n",
    "                #cropped_image = np_image\n",
    "                cropped_image, temp_bbox, size, boundary = crop_image(np_image, cow_bbox, label)\n",
    "                cow_result = []\n",
    "                cow_result.append({'bbox': [0, 0, 255, 255]})\n",
    "                preds, _ = process_model(model_leg_front, dataset_leg_front, cow_result, cropped_image)\n",
    "                draw = vis_pose(preds, draw, 'Leg_front', temp_bbox, size, boundary)\n",
    "            elif label == 'tail':\n",
    "                extend_rate = 0.05\n",
    "                np_image = np.array(temp_image)\n",
    "                tail_bbox = list(extend_bbox(box['Left'], box['Top'], box['Width'], box['Height'], extend_rate))\n",
    "                cropped_image, temp_bbox, size, boundary = crop_image(np_image, tail_bbox, label)\n",
    "                tail_result = []\n",
    "                tail_result.append({'bbox': [0, 0, 255, 255]})\n",
    "                preds, _ = process_model(model_tail, dataset_tail, tail_result, cropped_image)\n",
    "                draw = vis_pose(preds, draw, 'Tail', temp_bbox, size, boundary)\n",
    "                tail_check = True\n",
    "#*****\n",
    "    \n",
    "    img = np.asarray(image)[:,:,::-1].copy()\n",
    "    #inferred_frame = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "embedded-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzeVideo(src_video, src_bbox_json, src_img_dir, output_file, fps=5):\n",
    "    \n",
    "    start = time.time()\n",
    "        #imgWidth, imgHeight = image.size\n",
    "    with Image.open(src_img_dir+'0.jpg') as img:\n",
    "        imgWidth, imgHeight = img.size\n",
    "        imgSize = (imgWidth, imgHeight)\n",
    "        img.close()\n",
    "    cap = cv2.VideoCapture(src_video)\n",
    "    frameRate = cap.get(fps) #frame rate\n",
    "    print('FrameRate:', frameRate)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    videoWriter = cv2.VideoWriter(output_file, fourcc, frameRate, imgSize) \n",
    "    \n",
    "    with open(src_bbox_json) as bbox_json:\n",
    "        bbox_frames = json.load(bbox_json)\n",
    "        for frameId, bbox_data in enumerate(bbox_frames['Frames']):\n",
    "            # get each image frame\n",
    "            with Image.open(src_img_dir+str(frameId)+'.jpg') as img:\n",
    "                inferred_frame = draw_response(img, bbox_data, animal_target='cow')\n",
    "                #inferred_frame = cv2.cvtColor(inferred_frame, cv2.COLOR_BGR2RGB)\n",
    "#                 print(inferred_frame)\n",
    "#                 inferred_frame.save('./'+'image.jpg')\n",
    "                # uncommet this part for testing\n",
    "#                 if frameId == 450:\n",
    "#                     temp_frame = cv2.cvtColor(inferred_frame, cv2.COLOR_BGR2RGB)\n",
    "#                     temp_image = Image.fromarray(temp_frame)\n",
    "#                     temp_image.save('./'+'temp_image.jpg')\n",
    "#                     break\n",
    "                # check each 50 frame\n",
    "                if frameId % 50 == 0:\n",
    "                    print(\"Finish Processing {} frame\".format(frameId))\n",
    "                    plt.title(\"Frame {}\".format(int(frameId)))\n",
    "                    plt.savefig('debug_imgs/check_{}.jpg'.format(frameId), dpi=200)\n",
    "                    lap = time.time()\n",
    "                    print('lap time: ', lap - start)\n",
    "                videoWriter.write(inferred_frame)\n",
    "                img.close()\n",
    "\n",
    "    videoWriter.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    bbox_json.close()\n",
    "    \n",
    "    #end time\n",
    "    end = time.time()\n",
    "    print('total time lapse', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-algebra",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_data/inferred_video/inferred_v2_IMG_4195.mp4\n",
      "FrameRate: 30.007010983874736\n",
      "[[[207 207 205]\n",
      "  [201 201 199]\n",
      "  [193 193 191]\n",
      "  ...\n",
      "  [251 255 255]\n",
      "  [251 255 255]\n",
      "  [251 255 255]]\n",
      "\n",
      " [[201 201 199]\n",
      "  [199 199 197]\n",
      "  [196 196 194]\n",
      "  ...\n",
      "  [251 255 255]\n",
      "  [251 255 255]\n",
      "  [251 255 255]]\n",
      "\n",
      " [[197 197 195]\n",
      "  [197 197 195]\n",
      "  [199 199 197]\n",
      "  ...\n",
      "  [251 255 255]\n",
      "  [251 255 255]\n",
      "  [251 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[175 203 227]\n",
      "  [193 221 245]\n",
      "  [187 217 241]\n",
      "  ...\n",
      "  [179 188 205]\n",
      "  [181 188 204]\n",
      "  [182 188 204]]\n",
      "\n",
      " [[200 228 252]\n",
      "  [191 219 243]\n",
      "  [164 194 218]\n",
      "  ...\n",
      "  [176 185 202]\n",
      "  [178 185 201]\n",
      "  [178 184 200]]\n",
      "\n",
      " [[174 202 226]\n",
      "  [149 177 201]\n",
      "  [124 154 178]\n",
      "  ...\n",
      "  [173 182 199]\n",
      "  [174 181 197]\n",
      "  [175 181 197]]]\n",
      "Finish Processing 0 frame\n",
      "lap time:  0.46831345558166504\n",
      "[[[177 182 185]\n",
      "  [196 201 204]\n",
      "  [177 183 183]\n",
      "  ...\n",
      "  [251 255 255]\n",
      "  [251 255 255]\n",
      "  [251 255 255]]\n",
      "\n",
      " [[179 184 187]\n",
      "  [197 202 205]\n",
      "  [178 184 184]\n",
      "  ...\n",
      "  [251 255 255]\n",
      "  [251 255 255]\n",
      "  [251 255 255]]\n",
      "\n",
      " [[178 183 186]\n",
      "  [196 201 204]\n",
      "  [177 183 183]\n",
      "  ...\n",
      "  [251 255 255]\n",
      "  [251 255 255]\n",
      "  [251 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[151 179 201]\n",
      "  [130 158 180]\n",
      "  [108 136 158]\n",
      "  ...\n",
      "  [158 184 201]\n",
      "  [158 184 201]\n",
      "  [166 192 209]]\n",
      "\n",
      " [[100 128 150]\n",
      "  [ 97 125 147]\n",
      "  [102 130 152]\n",
      "  ...\n",
      "  [167 193 210]\n",
      "  [168 194 211]\n",
      "  [172 198 215]]\n",
      "\n",
      " [[110 138 160]\n",
      "  [114 142 164]\n",
      "  [122 150 172]\n",
      "  ...\n",
      "  [175 201 218]\n",
      "  [172 198 215]\n",
      "  [161 187 204]]]\n",
      "[[[173 179 179]\n",
      "  [173 179 179]\n",
      "  [175 181 181]\n",
      "  ...\n",
      "  [251 255 255]\n",
      "  [251 255 255]\n",
      "  [251 255 255]]\n",
      "\n",
      " [[172 178 178]\n",
      "  [172 178 178]\n",
      "  [174 180 180]\n",
      "  ...\n",
      "  [251 255 255]\n",
      "  [251 255 255]\n",
      "  [251 255 255]]\n",
      "\n",
      " [[171 177 177]\n",
      "  [172 178 178]\n",
      "  [174 180 180]\n",
      "  ...\n",
      "  [251 255 255]\n",
      "  [251 255 255]\n",
      "  [251 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[151 178 205]\n",
      "  [156 183 210]\n",
      "  [155 182 209]\n",
      "  ...\n",
      "  [171 199 220]\n",
      "  [170 198 219]\n",
      "  [164 192 213]]\n",
      "\n",
      " [[170 197 224]\n",
      "  [173 200 227]\n",
      "  [178 205 232]\n",
      "  ...\n",
      "  [163 191 212]\n",
      "  [161 189 210]\n",
      "  [167 195 216]]\n",
      "\n",
      " [[158 185 212]\n",
      "  [161 188 215]\n",
      "  [174 201 228]\n",
      "  ...\n",
      "  [193 221 242]\n",
      "  [178 206 227]\n",
      "  [167 195 216]]]\n"
     ]
    }
   ],
   "source": [
    "# main function\n",
    "video_name_list = ['IMG_4195']\n",
    "video_format = ['.mov']\n",
    "for v_idx, video in enumerate(video_name_list):\n",
    "    src_video = 'video_data/input_video/'+video+video_format[v_idx]\n",
    "    src_bbox_json = 'json_data/'+video+'_new_bbox.json'\n",
    "    src_img_dir = 'frame_img/'+video+'/'\n",
    "    output_video = 'video_data/inferred_video/inferred_v2_'+video+'.mp4'\n",
    "    print(output_video)\n",
    "    analyzeVideo(src_video, src_bbox_json, src_img_dir, output_video)\n",
    "    print('finished analyzing the video '+video)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-location",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p36] *",
   "language": "python",
   "name": "conda-env-pytorch_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
