{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "young-potter",
   "metadata": {},
   "source": [
    "## Import all Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "satellite-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS Rekognition to get bbox\n",
    "import numpy as np\n",
    "import boto3\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from utils.rekognition import determine_color, draw_animal_count\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "import pandas as pd\n",
    "from utils.config import *\n",
    "from utils.fix_annotation import *\n",
    "from collections import namedtuple\n",
    "Rectangle = namedtuple('Rectangle', 'xmin ymin xmax ymax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "employed-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process whole image.py to get key points\n",
    "import mmcv\n",
    "from mmcv.parallel import collate, scatter\n",
    "from mmcv.runner import load_checkpoint\n",
    "import torch as tr\n",
    "#from torchvision import transforms\n",
    "from mmpose.apis import (inference, inference_top_down_pose_model, init_pose_model,\n",
    "                         vis_pose_result)\n",
    "from mmpose.models import build_posenet\n",
    "from mmpose.datasets.pipelines import Compose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-marble",
   "metadata": {},
   "source": [
    "## Get Bounding Boxes from Video Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "union-lloyd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadImage:\n",
    "    \"\"\"A simple pipeline to load image.\"\"\"\n",
    "\n",
    "    def __init__(self, color_type='color', channel_order='rgb'):\n",
    "        self.color_type = color_type\n",
    "        self.channel_order = channel_order\n",
    "\n",
    "    def __call__(self, results):\n",
    "        \"\"\"Call function to load images into results.\n",
    "        Args:\n",
    "            results (dict): A result dict contains the img_or_path.\n",
    "        Returns:\n",
    "            dict: ``results`` will be returned containing loaded image.\n",
    "        \"\"\"\n",
    "        if isinstance(results['img_or_path'], str):\n",
    "            results['image_file'] = results['img_or_path']\n",
    "            img = mmcv.imread(results['img_or_path'], self.color_type,\n",
    "                              self.channel_order)\n",
    "        elif isinstance(results['img_or_path'], np.ndarray):\n",
    "            results['image_file'] = ''\n",
    "            if self.color_type == 'color' and self.channel_order == 'rgb':\n",
    "                img = cv2.cvtColor(results['img_or_path'], cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            raise TypeError('\"img_or_path\" must be a numpy array or a str or '\n",
    "                            'a pathlib.Path object')\n",
    "        results['img'] = img\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "important-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_pose_model(config, checkpoint=None, device='cuda:0'):\n",
    "    \"\"\"Initialize a pose model from config file.\n",
    "    Args:\n",
    "        config (str or :obj:`mmcv.Config`): Config file path or the config\n",
    "            object.\n",
    "        checkpoint (str, optional): Checkpoint path. If left as None, the model\n",
    "            will not load any weights.\n",
    "    Returns:\n",
    "        nn.Module: The constructed detector.\n",
    "    \"\"\"\n",
    "    if isinstance(config, str):\n",
    "        config = mmcv.Config.fromfile(config)\n",
    "    elif not isinstance(config, mmcv.Config):\n",
    "        raise TypeError('config must be a filename or Config object, '\n",
    "                        f'but got {type(config)}')\n",
    "    config.model.pretrained = None\n",
    "    model = build_posenet(config.model)\n",
    "    if checkpoint is not None:\n",
    "        # load model checkpoint\n",
    "        load_checkpoint(model, checkpoint, map_location=device)\n",
    "    # save the config in the model for convenience\n",
    "    model.cfg = config\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "administrative-philip",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _box2cs(cfg, box):\n",
    "    \"\"\"This encodes bbox(x,y,w,h) into (center, scale)\n",
    "    Args:\n",
    "        x, y, w, h\n",
    "    Returns:\n",
    "        tuple: A tuple containing center and scale.\n",
    "        - np.ndarray[float32](2,): Center of the bbox (x, y).\n",
    "        - np.ndarray[float32](2,): Scale of the bbox w & h.\n",
    "    \"\"\"\n",
    "\n",
    "    x, y, w, h = box[:4]\n",
    "    input_size = cfg.data_cfg['image_size']\n",
    "    aspect_ratio = input_size[0] / input_size[1]\n",
    "    center = np.array([x + w * 0.5, y + h * 0.5], dtype=np.float32)\n",
    "\n",
    "    if w > aspect_ratio * h:\n",
    "        h = w * 1.0 / aspect_ratio\n",
    "    elif w < aspect_ratio * h:\n",
    "        w = h * aspect_ratio\n",
    "\n",
    "    # pixel std is 200.0\n",
    "    scale = np.array([w / 200.0, h / 200.0], dtype=np.float32)\n",
    "\n",
    "    scale = scale * 1.25\n",
    "\n",
    "    return center, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sized-hebrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_model(model, dataset, person_results, img_or_path):\n",
    "    bboxes = np.array([box['bbox'] for box in person_results])\n",
    "    cfg = model.cfg\n",
    "    flip_pairs = None\n",
    "    device = next(model.parameters()).device\n",
    "    channel_order = cfg.test_pipeline[0].get('channel_order', 'rgb')\n",
    "    test_pipeline = [LoadImage(channel_order=channel_order)] + cfg.test_pipeline[1:]\n",
    "    test_pipeline = Compose(test_pipeline)\n",
    "    if dataset == 'AnimalHorse10Dataset':\n",
    "        flip_pairs = []\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "    batch_data = []\n",
    "    for bbox in bboxes:\n",
    "        center, scale = _box2cs(cfg, bbox)\n",
    "        # prepare data\n",
    "        data = {\n",
    "            'img_or_path':\n",
    "            img_or_path,\n",
    "            'center':\n",
    "            center,\n",
    "            'scale':\n",
    "            scale,\n",
    "            'bbox_score':\n",
    "            bbox[4] if len(bbox) == 5 else 1,\n",
    "            'bbox_id':\n",
    "            0,  # need to be assigned if batch_size > 1\n",
    "            'dataset':\n",
    "            dataset,\n",
    "            'joints_3d':\n",
    "            np.zeros((cfg.data_cfg.num_joints, 3), dtype=np.float32),\n",
    "            'joints_3d_visible':\n",
    "            np.zeros((cfg.data_cfg.num_joints, 3), dtype=np.float32),\n",
    "            'rotation':\n",
    "            0,\n",
    "            'ann_info': {\n",
    "                'image_size': np.array(cfg.data_cfg['image_size']),\n",
    "                'num_joints': cfg.data_cfg['num_joints'],\n",
    "                'flip_pairs': flip_pairs\n",
    "            }\n",
    "        }\n",
    "        data = test_pipeline(data)\n",
    "        batch_data.append(data)\n",
    "    batch_data = collate(batch_data, samples_per_gpu=1)\n",
    "    if next(model.parameters()).is_cuda:\n",
    "        # scatter not work so just move image to cuda device\n",
    "        batch_data['img'] = batch_data['img'].to(device)\n",
    "    # get all img_metas of each bounding box\n",
    "    batch_data['img_metas'] = [\n",
    "        img_metas[0] for img_metas in batch_data['img_metas'].data]\n",
    "\n",
    "    with tr.no_grad():\n",
    "        result = model(\n",
    "            img=batch_data['img'],\n",
    "            #img = torch_data,\n",
    "            img_metas=batch_data['img_metas'],\n",
    "            return_loss=False,\n",
    "            return_heatmap=False)\n",
    "    return result['preds'], result['output_heatmap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "brutal-database",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Use load_from_local loader\n",
      "Use load_from_local loader\n",
      "Use load_from_local loader\n",
      "Use load_from_local loader\n",
      "Use load_from_local loader\n"
     ]
    }
   ],
   "source": [
    "device = tr.device(\"cuda:0\" if tr.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model_head = init_pose_model(config='../my_configs/cattle/resnet_50_10/head_black.py', checkpoint='../train_result/cattle/resnet_50_10/head_black/best.pth', device = device)\n",
    "model_spine = init_pose_model(config='../my_configs/cattle/resnet_50_5/spine_black.py', checkpoint='../train_result/cattle/resnet_50_5/spine_black/best.pth', device = device)\n",
    "model_tail = init_pose_model(config='../my_configs/cattle/resnet_50_5/tail_black.py', checkpoint='../train_result/cattle/resnet_50_5/tail_black/best.pth', device = device)\n",
    "model_leg_front = init_pose_model(config='../my_configs/cattle/resnet_50_10/leg_front_black.py', checkpoint='../train_result/cattle/resnet_50_10/leg_front_black/best.pth', device = device)\n",
    "model_leg_back = init_pose_model(config='../my_configs/cattle/resnet_50_5/leg_back_black.py', checkpoint='../train_result/cattle/resnet_50_5/leg_back_black/best.pth', device = device)\n",
    "\n",
    "dataset_head = model_head.cfg.data['test']['type']\n",
    "dataset_spine = model_spine.cfg.data['test']['type']\n",
    "dataset_tail = model_tail.cfg.data['test']['type']\n",
    "dataset_leg_front = model_leg_front.cfg.data['test']['type']\n",
    "dataset_leg_back = model_leg_back.cfg.data['test']['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "printable-geology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kp_color(label):\n",
    "    # BGR\n",
    "    color = (0, 0, 255)\n",
    "    if label == 'Head':\n",
    "        color = ['#EC51F8', '#74F54B', \n",
    "                 '#EC51F8', '#74F54B',\n",
    "                 '#4394F9', '#F49736',\n",
    "                 '#F49736', '#FFFB56',\n",
    "                 '#FFFB56', '#4394F9',\n",
    "                 '#07178D']\n",
    "    elif label == 'Spine':\n",
    "          color = ['#4394F9', '#4394F9', '#4394F9',\n",
    "                  '#4394F9', '#4394F9', '#4394F9', \n",
    "                  '#4394F9', '#4394F9', '#24518D']\n",
    "    elif label == 'Tail':\n",
    "        color = ['#EC51F8', '#EC51F8',\n",
    "                '#EC51F8', '#EC51F8',\n",
    "                '#EC51F8', '#892B8E']\n",
    "    elif label == 'Leg_front':\n",
    "        color = ['#F49736', '#F49736',\n",
    "                '#F49736', '#F49736',\n",
    "                '#F49736', '#F49736',\n",
    "                '#F49736', '#F49736',\n",
    "                '#F49736', '#8C551E']\n",
    "    elif label == 'Leg_back':\n",
    "        color = ['#74F54B', '#74F54B',\n",
    "                '#74F54B', '#74F54B',\n",
    "                '#74F54B', '#74F54B',\n",
    "                '#74F54B', '#74F54B',\n",
    "                '#74F54B', '#3F8D28',]\n",
    "    return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "grand-impossible",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skeleton(label):\n",
    "    skeleton_list = []\n",
    "    if label == 'Head':\n",
    "        skeleton_list = [[4, 0], [4, 2], [0, 2], [1, 3], \n",
    "                        [5, 6], [7, 8], [0, 1], [1, 5],\n",
    "                        [5, 7], [7, 9], [2, 3], [3, 6],\n",
    "                        [6, 8], [8, 9], [4, 9]]\n",
    "    elif label == 'Spine':\n",
    "        skeleton_list = [[0, 1], [1, 2], [2, 3], [3, 4],\n",
    "                        [4, 5], [5, 6], [6, 7]]\n",
    "    elif label == 'Tail':\n",
    "        skeleton_list = [[0, 1], [1, 2], [2, 3], [3, 4]]\n",
    "    elif label == 'Leg_front':\n",
    "        skeleton_list = [[0, 1], [1, 2], [2, 3], [3, 4],\n",
    "                        [4, 5], [5, 6], [6, 7], [7, 8]]\n",
    "    elif label == 'Leg_back':\n",
    "        skeleton_list = [[0, 1], [1, 2], [2, 3], [3, 4],\n",
    "                        [4, 5], [5, 6], [6, 7], [7, 8]]\n",
    "    return skeleton_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "filled-hollywood",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kp_name(label, i):\n",
    "    name_list = []\n",
    "    if label == 'Head':\n",
    "        name_list = [\"Ear_Tip_Ri\", \"Ear_Base_R\", \"Ear_Tip_Le\", \"Ear_Base_L\", \n",
    "                     \"Head_Top\", \"Eye_Right\", \"Eye_Left\", \"Nostril_Ri\", \n",
    "                     \"Nostril_Le\", \"Mouth_Bott\"]\n",
    "    elif label == 'Spine':\n",
    "        name_list = [\"Head\", \"Neck\", \"Shoulder F\", \"Arch 1\", \n",
    "                     \"Arch Mid\", \"Arch 3\", \"Should Bac\", \"Tail\"]\n",
    "    elif label == 'Tail':\n",
    "        name_list = [\"Tail Start\", \"Tail 1/4\", \"Tail half\", \"Tail 3/4\", \"Tail End\"]\n",
    "    elif label == 'Leg_front':\n",
    "        name_list = [\"Right Hoof\", \"Right Ankl\", \"Right Knee\", \"Right Hip\", \n",
    "                     \"Shoulder\", \"Left Hip\", \"Left Knee\", \"Left Ankle\", \n",
    "                     \"Left Hoof\"]\n",
    "    elif label == 'Leg_back':\n",
    "        name_list = [\"Right Hoof\", \"Right Ankle\", \"Right Knee\", \"Right Hip\", \n",
    "                     \"Shoulder\", \"Left Hip\", \"Left Knee\", \"Left Ankle\", \n",
    "                     \"Left Hoof\"]\n",
    "    return name_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "underlying-paper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_bgr(color):\n",
    "    color = list(color)\n",
    "    temp_r = color[0]\n",
    "    color[0] = color[2]\n",
    "    color[2] = temp_r\n",
    "    return tuple(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "comparative-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angle(a, b, c):\n",
    "    ang = math.degrees(math.atan2(\n",
    "        c[1]-b[1], c[0]-b[0]) - math.atan2(a[1]-b[1], a[0]-b[0]))\n",
    "    \n",
    "    return ang + 360 if ang < 0 else ang\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "closed-vehicle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_to_bgr(color_str):\n",
    "    # convert color\n",
    "    hex_color = color_str.lstrip(\"#\")\n",
    "    # convert outline color\n",
    "    # bgr: 4, 2, 0 or rgb: 0, 2, 4\n",
    "    return tuple(int(hex_color[i:i+2], 16) for i in (4, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "structural-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shift(radius, angle):\n",
    "    x = radius * math.cos(math.radians(angle))\n",
    "    y = radius * math.sin(math.radians(angle))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "electoral-flavor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbox_type(label):\n",
    "    bbox_type = 'head'\n",
    "    if label == 'Spine' or label == 'Leg_front' or label == 'Leg_back':\n",
    "        bbox_type = 'cow'\n",
    "    elif label == 'Tail':\n",
    "        bbox_type = 'tail'\n",
    "    return bbox_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "limited-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_angle(point_1, point_2, point_3, filp):\n",
    "    angle = 360 - get_angle(point_1, point_2, point_3)\n",
    "    # pieslice bbox\n",
    "    delta_x = point_3[0] - point_2[0]\n",
    "    delta_y = point_3[1] - point_2[1]\n",
    "    if filp:\n",
    "        # return to original angle\n",
    "        angle = -1 * angle + 360\n",
    "        delta_x = point_1[0] - point_2[0]\n",
    "        delta_y = point_1[1] - point_2[1]\n",
    "    start_angle = math.degrees(math.atan2(delta_y, delta_x))\n",
    "    end_angle = start_angle + round(angle)\n",
    "    mid_angle = start_angle + round(angle) / 2\n",
    "    return angle, start_angle, end_angle, mid_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "russian-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_filled_angle(img, x, y, angle_list, shift_list, shift_text_list, fill_color, broder_color, fill_opacity, opacity_adjust=0, radius=40):\n",
    "    # draw filled angle\n",
    "    shapes = np.zeros_like(img, np.uint8)\n",
    "#     cv2.ellipse(shapes, (int(x+shift_list[0]), int(y+shift_list[1])), (radius, radius), 0, int(angle_list[1]), int(angle_list[2]), fill_color, cv2.FILLED)\n",
    "    cv2.ellipse(shapes, (int(x + shift_list[0]), int(y + shift_list[1])), \n",
    "                (radius, radius), 0, angle_list[1], angle_list[2], \n",
    "                fill_color, cv2.FILLED)\n",
    "    mask = shapes.astype(bool)\n",
    "    img[mask] = cv2.addWeighted(img, 1 - fill_opacity + opacity_adjust, \n",
    "                                shapes, fill_opacity, 0)[mask]\n",
    "    # edge\n",
    "    cv2.ellipse(img, (int(x+shift_list[0]), int(y + shift_list[1])), (radius, radius), 0, \n",
    "                angle_list[1], angle_list[2], broder_color, 2)\n",
    "    # draw start angle outline\n",
    "    start_point = (int(x + shift_list[0]), int(y + shift_list[1]))\n",
    "    end_point = (int(x + shift_list[0] + radius * math.cos(math.radians(angle_list[1]))),\n",
    "                 int(y + shift_list[1] + radius * math.sin(math.radians(angle_list[1]))))\n",
    "    cv2.line(img, start_point, end_point, broder_color, 2)\n",
    "    # draw end angle outline\n",
    "    end_point = (int(x + shift_list[0] + radius * math.cos(math.radians(angle_list[2]))),\n",
    "                 int(y + shift_list[1] + radius * math.sin(math.radians(angle_list[2]))))\n",
    "    cv2.line(img, start_point, end_point, broder_color, 2)\n",
    "    # draw full angle\n",
    "    angle_str = \"{:.0f}\".format(angle_list[0])\n",
    "    angle_str_len = len(angle_str)\n",
    "    cv2.putText(img, angle_str, (int(x+shift_list[0])+shift_text_list[0], int(y)+shift_text_list[1]), \n",
    "                cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "    cv2.ellipse(img, (int(x+shift_list[0]+shift_text_list[0]+angle_str_len*12), int(y-8)+shift_text_list[1]), \n",
    "                (3, 3), 0, 0, 360, (255, 255, 255), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "minimal-holmes",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_pose(points, img, label, frameId, data_list, CS_THR=0.4):\n",
    "    # keypoints\n",
    "    kp_color = get_kp_color(label)\n",
    "    # connect line\n",
    "    skeleton_list = get_skeleton(label)\n",
    "    for ske in skeleton_list:\n",
    "        fir_pt_x, fir_pt_y, fir_pt_p = points[ske[0]]\n",
    "        sec_pt_x, sec_pt_y, sec_pt_p = points[ske[1]]\n",
    "        if fir_pt_p > CS_THR and sec_pt_p > CS_THR:\n",
    "            # draw line\n",
    "            start_point = (int(fir_pt_x), int(fir_pt_y))\n",
    "            end_point = (int(sec_pt_x), int(sec_pt_y))\n",
    "            bgr_color = hex_to_bgr(kp_color[-1])\n",
    "            cv2.line(img, start_point, end_point, bgr_color, 5)\n",
    "    \n",
    "    for i, point in enumerate(points):\n",
    "        x, y, p = point\n",
    "        if p > CS_THR:\n",
    "            x = int(x)\n",
    "            y = int(y)\n",
    "            bgr_color = hex_to_bgr(kp_color[i])\n",
    "            # draw kp\n",
    "            cv2.ellipse(img, (x, y), (5, 5), 0, 0, 360, bgr_color, cv2.FILLED)\n",
    "            # draw kp outline\n",
    "            bgr_color = hex_to_bgr(kp_color[-1])\n",
    "            cv2.ellipse(img, (x, y), (7, 7), 0, 0, 360, bgr_color, 2)\n",
    "#             cv2.putText(img, str(i), (x-20, y-20), \n",
    "#                         cv2.FONT_HERSHEY_COMPLEX, 0.5, (255, 255, 255), \n",
    "#                         1, cv2.LINE_AA)\n",
    "            #***init keypoint data\n",
    "#             bbox_type = get_bbox_type(label)\n",
    "            kp_data_list = [frameId, get_kp_name(label, i), x, y, 0]\n",
    "            #***\n",
    "            # draw spine angle\n",
    "            if (label == 'Spine') and i > 0 and i < 7 and points[i-1][2] > CS_THR and points[i+1][2] > CS_THR:\n",
    "                delta_x = points[i-1][0] - points[i][0]\n",
    "                angle, start_angle, end_angle, mid_angle = get_all_angle(points[i+1], points[i], points[i-1], delta_x > 0)\n",
    "                kp_data_list[-1] = angle\n",
    "                shift_text_list = [-20, -22]\n",
    "                shift_x, shift_y = get_shift(10, mid_angle)\n",
    "                shift_list = [shift_x, shift_y]\n",
    "                angle_list = [angle, start_angle, end_angle, mid_angle]\n",
    "                draw_filled_angle(img, x, y, angle_list, shift_list, shift_text_list, \n",
    "                                  hex_to_bgr('#4394F9'), hex_to_bgr('#4394F9'), 0.8)\n",
    "            # draw ear angle\n",
    "            elif (label == 'Head'):\n",
    "                # draw angle for point 1 of head\n",
    "                if i == 1 and points[0][2] > CS_THR and points[1][2] > CS_THR and points[3][2] > CS_THR:\n",
    "                    # cacluate the angle of opposite side\n",
    "                    delta_x = points[3][0] - points[1][0]\n",
    "                    angle, start_angle, end_angle, mid_angle = get_all_angle(points[0], points[1], points[3], delta_x > 0)\n",
    "                    kp_data_list[-1] = angle\n",
    "                    shift_text_list = [-15, -15]\n",
    "                    shift_x, shift_y = get_shift(10, mid_angle)\n",
    "                    shift_list = [shift_x, shift_y]\n",
    "                    angle_list = [angle, start_angle, end_angle, mid_angle]\n",
    "                    draw_filled_angle(img, x, y, angle_list, shift_list, shift_text_list, \n",
    "                                      hex_to_bgr('#4394F9'), hex_to_bgr('#4394F9'), 0.8)\n",
    "                # draw angle for point 3 of head\n",
    "                if i == 3 and points[1][2] > CS_THR and points[2][2] > CS_THR and points[3][2] > CS_THR:\n",
    "                    # cacluate the angle of opposite side\n",
    "                    delta_x = points[2][0] - points[3][0]\n",
    "                    angle, start_angle, end_angle, mid_angle = get_all_angle(points[1], points[3], points[2], delta_x > 0)\n",
    "                    kp_data_list[-1] = angle\n",
    "                    shift_text_list = [-15, -15]\n",
    "                    shift_x, shift_y = get_shift(10, mid_angle)\n",
    "                    shift_list = [shift_x, shift_y]\n",
    "                    angle_list = [angle, start_angle, end_angle, mid_angle]\n",
    "                    draw_filled_angle(img, x, y, angle_list, shift_list, shift_text_list, \n",
    "                                      hex_to_bgr('#4394F9'), hex_to_bgr('#4394F9'), 0.8)\n",
    "            # draw tail angle\n",
    "            elif (label == 'Tail') and i > 0 and i < 4 and points[i-1][2] > CS_THR and points[i+1][2] > CS_THR and points[0][2] > CS_THR and points[1][2] > CS_THR:\n",
    "                filp = (points[0][0] - points[1][0] > 0)\n",
    "                angle, start_angle, end_angle, mid_angle = get_all_angle(points[i+1], points[i], points[i-1], filp)\n",
    "                kp_data_list[-1] = angle\n",
    "                shift_text_list = [0, 5]\n",
    "                shift_x, shift_y = get_shift(10, mid_angle)\n",
    "                shift_list = [shift_x, shift_y]\n",
    "                angle_list = [angle, start_angle, end_angle, mid_angle]\n",
    "                if filp:\n",
    "                    shift_text_list[0] = -40\n",
    "                draw_filled_angle(img, x, y, angle_list, shift_list, shift_text_list, \n",
    "                                  hex_to_bgr('#EC51F8'), hex_to_bgr('#EC51F8'), 0.8)\n",
    "            # draw leg angle\n",
    "            elif (label == 'Leg_front' or label == 'Leg_back') and i > 0 and i < 8 and points[i-1][2] > CS_THR and points[i+1][2] > CS_THR:\n",
    "                filp = not (i >= 5 or (i == 4 and points[5][0] < points[3][0]))\n",
    "                angle, start_angle, end_angle, mid_angle = get_all_angle(points[i+1], points[i], points[i-1], filp)\n",
    "                kp_data_list[-1] = angle\n",
    "                shift_text_list = [0, 5]\n",
    "                shift_dis = 10\n",
    "                if i == 4:\n",
    "                    shift_text_list[0] = 12\n",
    "                    shift_dis = 15\n",
    "                if i == 1 or i == 7:\n",
    "                    shift_text_list[1] = 0\n",
    "                shift_x, shift_y = get_shift(shift_dis, mid_angle)\n",
    "                shift_list = [shift_x, shift_y]\n",
    "                angle_list = [angle, start_angle, end_angle, mid_angle]\n",
    "                draw_filled_angle(img, x, y, angle_list, shift_list, shift_text_list, \n",
    "                                      hex_to_bgr('#FF9300'), hex_to_bgr('#FF9300'), 0.8, opacity_adjust=0.2)\n",
    "                \n",
    "            data_list.append(kp_data_list)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "confirmed-client",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_mutual_angle(pred_1, pred_2, label_1, label_2, img, frameId, data_list, CS_THR=0.4):\n",
    "    pred_1_idx = 4\n",
    "    if label_1 == 'Head' and label_2 == 'Spine':\n",
    "        x1, y1, p1 = pred_1[pred_1_idx]\n",
    "        x2, y2, p2 = pred_2[0]\n",
    "        x3, y3, p3 = pred_1[9]\n",
    "        x4, y4, p4 = pred_2[1]\n",
    "        color_code = '#4394F9'\n",
    "    elif label_1 == 'Tail' and label_2 == 'Spine':\n",
    "        pred_1_idx = 0\n",
    "        x1, y1, p1 = pred_1[pred_1_idx]\n",
    "        x2, y2, p2 = pred_2[7]\n",
    "        x3, y3, p3 = pred_1[1]\n",
    "        x4, y4, p4 = pred_2[6]\n",
    "        color_code = '#EC51F8'\n",
    "    else:\n",
    "        print('no matched label')\n",
    "        return img\n",
    "\n",
    "    if p3 <= CS_THR or p4 <= CS_THR or (p1 <= CS_THR and p2 <= CS_THR):\n",
    "        return img\n",
    "    if p1 > CS_THR and p2 <= CS_THR:\n",
    "        x2, y2, p2 = x1, y1, p1\n",
    "    elif p2 > CS_THR and p1 <= CS_THR:\n",
    "        x1, y1, p1 = x2, y2, p2\n",
    "    bbox_type_1 = get_bbox_type(label_1)\n",
    "    bbox_type_2 = get_bbox_type(label_2)\n",
    "    mid_point_x = int((x1 + x2) / 2)\n",
    "    mid_point_y = int((y1 + y2) / 2)\n",
    "    # draw angle\n",
    "    filp = (x4-x2 > 0)\n",
    "    angle, start_angle, end_angle, mid_angle = get_all_angle([x3, y3], [mid_point_x, mid_point_y], [x4, y4], filp)\n",
    "    kp_data_list = [frameId, get_kp_name(label_1, pred_1_idx), mid_point_x, mid_point_y, 0]\n",
    "    kp_data_list[-1] = angle\n",
    "    shift_text_list = [5, -8]\n",
    "    shift_x, shift_y = get_shift(10, mid_angle)\n",
    "    shift_list = [shift_x, shift_y]\n",
    "    angle_list = [angle, start_angle, end_angle, mid_angle]\n",
    "    if filp:\n",
    "        shift_text_list[0] = -25\n",
    "    draw_filled_angle(img, mid_point_x, mid_point_y, angle_list, shift_list, shift_text_list, \n",
    "                      hex_to_bgr(color_code), hex_to_bgr(color_code), 0.8)\n",
    "\n",
    "    data_list.append(kp_data_list)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bizarre-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_bbox(left, top, width, height, extend_rate, img_size):\n",
    "    temp_left = left - (width * extend_rate / 2)\n",
    "    if temp_left < 0:\n",
    "        temp_left = 0\n",
    "    temp_top = top - (height * extend_rate / 2)\n",
    "    if temp_top < 0:\n",
    "        temp_top = 0\n",
    "    temp_width = width + (width * extend_rate / 2)\n",
    "#     if temp_left+temp_width > img_size[0]-1:\n",
    "#         temp_width = img_size[0] - 1 - temp_left\n",
    "    temp_height = height + (height * extend_rate / 2)\n",
    "#     if temp_top+temp_height > img_size[1]-1:\n",
    "#         temp_height = img_size[1] - 1 - temp_top\n",
    "    #print(temp_left, temp_top, temp_width, temp_height)\n",
    "    return temp_left, temp_top, temp_width, temp_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "still-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color(name):\n",
    "    if name == 'cow' or name == 'animal':\n",
    "        color = '#FF9300'\n",
    "    elif name == 'head' or name == \"head left\" or name == \"head right\":\n",
    "        color = '#4394F9'\n",
    "    elif name == 'tag':\n",
    "        color = '#00FFFF'\n",
    "    elif name == 'knee':\n",
    "        color = '#FFFB00'\n",
    "    elif name == 'hoof':\n",
    "        color = '#00F900'\n",
    "    elif name == 'tail':\n",
    "        color = '#FF40FF'\n",
    "    elif name == 'side left' or name == 'side right':\n",
    "        color = '#FF2600'\n",
    "    elif name == 'udder':\n",
    "        color = '#9437FF'\n",
    "    elif name == 'teat':\n",
    "        color = '#FF2F92'\n",
    "    else:\n",
    "        color = '#000000'\n",
    "    return color\n",
    "\n",
    "def get_opacity(name):\n",
    "    if name == 'cow' or name == 'animal':\n",
    "        opacity = 0.3\n",
    "    elif name == 'tag':\n",
    "        opacity = 0.3\n",
    "    elif name == 'head' or name == \"head Left\" or name == \"head Right\":\n",
    "        opacity = 0.45\n",
    "    elif name == 'knee':\n",
    "        opacity = 0.3\n",
    "    elif name == 'hoof':\n",
    "        opacity = 0.35\n",
    "    elif name == 'tail':\n",
    "        opacity = 0.3\n",
    "    elif name == 'side left' or name == 'side right':\n",
    "        opacity = 0.3\n",
    "    elif name == 'udder':\n",
    "        opacity = 0.35\n",
    "    elif name == 'teat':\n",
    "        opacity = 0.3\n",
    "    else:\n",
    "        opacity = 0.0\n",
    "\n",
    "    return opacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "celtic-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confidence_cut_off(name):\n",
    "    if name == 'cow':\n",
    "        confidence = 79.4\n",
    "    elif name == 'tag':\n",
    "        confidence = 86.9\n",
    "    elif name == 'head':\n",
    "        confidence = 92.5\n",
    "    elif name == 'knee':\n",
    "        confidence = 78.0\n",
    "    elif name == 'hoof':\n",
    "        confidence = 92.9\n",
    "    elif name == 'tail':\n",
    "        confidence = 73.5\n",
    "    elif name == 'udder':\n",
    "        confidence = 35.0\n",
    "    elif name == 'teat':\n",
    "        confidence = 73.0\n",
    "    elif name == 'animal':\n",
    "        confidence = 80.0\n",
    "    else:\n",
    "        confidence = 80.0\n",
    "\n",
    "    return confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aerial-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def image_resize(image, width = 256, height = 256, inter = cv2.INTER_AREA):\n",
    "#     # initialize the dimensions of the image to be resized and\n",
    "#     # grab the image size\n",
    "#     dim = None\n",
    "#     (h, w) = image.shape[:2]\n",
    "\n",
    "#     # if both the width and height are None, then return the\n",
    "#     # original image\n",
    "#     if width is None and height is None:\n",
    "#         return image\n",
    "\n",
    "#     # check to see if the width is None\n",
    "#     if width is None:\n",
    "#         # calculate the ratio of the height and construct the\n",
    "#         # dimensions\n",
    "#         r = height / float(h)\n",
    "#         dim = (int(w * r), height)\n",
    "\n",
    "#     # otherwise, the height is None\n",
    "#     else:\n",
    "#         # calculate the ratio of the width and construct the\n",
    "#         # dimensions\n",
    "#         r = width / float(w)\n",
    "#         dim = (width, int(h * r))\n",
    "        \n",
    "#     print(dim)\n",
    "\n",
    "#     # resize the image\n",
    "#     resized = cv2.resize(image, dim, interpolation = inter)\n",
    "\n",
    "#     # return the resized image\n",
    "#     return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "interior-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(image, bbox, label):\n",
    "    temp_bbox = [bbox[0], bbox[1], bbox[0]+bbox[2], bbox[1]+bbox[3]]\n",
    "    \n",
    "    ori_image = Image.fromarray(image, 'RGB')    \n",
    "    cropped_image = ori_image.copy().crop(temp_bbox)\n",
    "    # rescale images and annotations\n",
    "    size_x = 256\n",
    "    size_y = 256\n",
    "    \n",
    "    # Image.ANTIALIAS scale the cropped image (head)\n",
    "    ori_crop_size = cropped_image.size\n",
    "    cropped_image.thumbnail((size_x, size_y), Image.ANTIALIAS)\n",
    "    # scale keypoints\n",
    "    new_image = Image.new('RGB', (size_x, size_y), color = 'black')\n",
    "    new_image.paste(cropped_image)\n",
    "    cropped_image_size = cropped_image.size\n",
    "    scale_rate = (cropped_image_size[0]/ori_crop_size[0], cropped_image_size[1]/ori_crop_size[1])\n",
    "    new_image = np.array(new_image)\n",
    "    \n",
    "#     cropped_image = image[int(bbox[1]):int(bbox[1]+bbox[3]), int(bbox[0]):int(bbox[0]+bbox[2])]\n",
    "#     cv2.imwrite('color_img.jpg', cropped_image)\n",
    "# #     size_x = 256\n",
    "# #     size_y = 256\n",
    "# #     print(cropped_image.shape)\n",
    "# #     cropped_image_size = cropped_image.shape\n",
    "# #     imRes = cv2.resize(cropped_image, width=256, interpolation=cv2.INTER_AREA)\n",
    "# #     cv2.imwrite('shrink_image.jpg', imRes)\n",
    "#     cv2.imwrite('shrink_image.jpg', image_resize(cropped_image))\n",
    "    \n",
    "    return new_image, temp_bbox, cropped_image_size, scale_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "mineral-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_ori_cordinates(preds, temp_bbox, size, scale_rate):\n",
    "    #print(preds, temp_bbox, size, scale_rate)\n",
    "    points = preds[0]\n",
    "    for i, point in enumerate(points):\n",
    "        x, y, p = point\n",
    "        # point out of the bound\n",
    "        if x > size[0] or y > size[1]:\n",
    "            points[i][2] = 0\n",
    "        else:\n",
    "            points[i][0] = temp_bbox[0] + x / scale_rate[0]\n",
    "            points[i][1] = temp_bbox[1] + y / scale_rate[1]\n",
    "\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adult-relevance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overlap_area(a, b):  # returns None if rectangles don't intersect\n",
    "    dx = min(a.xmax, b.xmax) - max(a.xmin, b.xmin)\n",
    "    dy = min(a.ymax, b.ymax) - max(a.ymin, b.ymin)\n",
    "    if (dx>=0) and (dy>=0):\n",
    "        return dx*dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "united-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_line_connect(pred_1, pred_2, label_1, label_2, img, CS_THR=0.4):\n",
    "    if label_1 == 'Spine' and label_2 == 'Leg_front':\n",
    "        # keypoint color\n",
    "        kp_color = get_kp_color(label_1)\n",
    "        spine_kp_idx = 1\n",
    "        legf_kp_idx = 4\n",
    "        fir_pt_x, fir_pt_y, fir_pt_p = pred_1[spine_kp_idx]\n",
    "        sec_pt_x, sec_pt_y, sec_pt_p = pred_2[legf_kp_idx]\n",
    "        if fir_pt_p > CS_THR and sec_pt_p > CS_THR:\n",
    "            # draw line\n",
    "            start_point = (int(fir_pt_x), int(fir_pt_y))\n",
    "            end_point = (int(sec_pt_x), int(sec_pt_y))\n",
    "            bgr_color = hex_to_bgr(kp_color[-1])\n",
    "            cv2.line(img, start_point, end_point, bgr_color, 5)\n",
    "    elif label_1 == 'Spine' and label_2 == 'Leg_back':\n",
    "        # keypoint color\n",
    "        kp_color = get_kp_color(label_1)\n",
    "        spine_kp_idx = len(pred_1)-2\n",
    "        legb_kp_idx = 4\n",
    "        fir_pt_x, fir_pt_y, fir_pt_p = pred_1[spine_kp_idx]\n",
    "        sec_pt_x, sec_pt_y, sec_pt_p = pred_2[legb_kp_idx]\n",
    "        if fir_pt_p > CS_THR and sec_pt_p > CS_THR:\n",
    "            # draw line\n",
    "            start_point = (int(fir_pt_x), int(fir_pt_y))\n",
    "            end_point = (int(sec_pt_x), int(sec_pt_y))\n",
    "            bgr_color = hex_to_bgr(kp_color[-1])\n",
    "            cv2.line(img, start_point, end_point, bgr_color, 5)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "backed-mounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(pred_list, bbox_list, preds, pred_cur_idx, bbox, bbox_cur_idx, label, frameId, bbox_conf):\n",
    "    for i, pred in enumerate(preds):\n",
    "        pred_list.append([frameId, label, pred_cur_idx, i, pred[0], pred[1], pred[2]])\n",
    "    if label == 'Spine' or label == 'Head' or label == 'Tail':\n",
    "        bbox_list.append([frameId, label, bbox_cur_idx, bbox['Left'], bbox['Top'], bbox['Width'], bbox['Height'], bbox_conf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "trained-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw response\n",
    "def draw_response(img, response, animal_target, frameId, data_list, pred_list, bbox_list, draw_boundary=True, draw_fill=True, draw_btn=True):\n",
    "    ori_img = img.copy()\n",
    "#     for customLabel in response['CustomLabels']:\n",
    "#         if 'Geometry' in customLabel:\n",
    "#             box = customLabel['Geometry']['BoundingBox']\n",
    "#             left, top, width, height = extend_bbox(box['Left'], box['Top'], box['Width'], box['Height'], 0, ori_img.shape)\n",
    "#             label = customLabel['Name'].lower()\n",
    "#             conf_cut = get_confidence_cut_off(label)\n",
    "#             # skip current label\n",
    "#             if customLabel['Confidence'] < conf_cut:\n",
    "#                 continue\n",
    "#             #draw bbox\n",
    "#             color = get_color(label)\n",
    "# #             opacity = round(get_opacity(label) * 255)\n",
    "#             opacity = get_opacity(label)\n",
    "#             start_point = (int(left), int(top))\n",
    "#             end_point = (int(left+width), int(top+height))\n",
    "#             bgr_color =  hex_to_bgr(color)\n",
    "#             if draw_fill:\n",
    "#                 # Draw filled bbox\n",
    "#                 # Initialize blank mask image of same dimensions for drawing the shapes\n",
    "#                 shapes = np.zeros_like(img, np.uint8)\n",
    "#                 cv2.rectangle(shapes, start_point, end_point, bgr_color, cv2.FILLED)\n",
    "#                 mask = shapes.astype(bool)\n",
    "#                 img[mask] = cv2.addWeighted(img, 1-opacity+0.15, shapes, opacity, 0)[mask]\n",
    "#             if draw_boundary:\n",
    "#                 img = cv2.rectangle(img, start_point, end_point, bgr_color, 3)\n",
    "#             if draw_btn:\n",
    "#                 end_point = (int(left)+8+len(label)*10, int(top)+20)\n",
    "#                 img = cv2.rectangle(img, start_point, end_point, bgr_color, cv2.FILLED)\n",
    "#                 img = cv2.putText(img, label, (int(left)+5, int(top)+15), cv2.FONT_HERSHEY_COMPLEX, 0.50, (0,0,0), 1, cv2.LINE_AA)\n",
    "    \n",
    "    head_pred_list, spine_pred_list, legf_pred_list, legb_pred_list, tail_pred_list = [], [], [], [], []\n",
    "    head_bbox_list, spine_bbox_list, legf_bbox_list, legb_bbox_list, tail_bbox_list = [], [], [], [], []\n",
    "    #keypoints\n",
    "    for customLabel in response['CustomLabels']:\n",
    "        if 'Geometry' in customLabel:\n",
    "            box = customLabel['Geometry']['BoundingBox']\n",
    "            label = customLabel['Name'].lower()\n",
    "            #lower case for comparison\n",
    "            conf_cut = get_confidence_cut_off(label)\n",
    "            # skip current label\n",
    "            if customLabel['Confidence'] < conf_cut:\n",
    "                continue\n",
    "        #***** Keypoints\n",
    "            if label == 'head':\n",
    "                extend_rate = 0.1\n",
    "                np_image = np.array(ori_img)\n",
    "                head_bbox = list(extend_bbox(box['Left'], box['Top'], box['Width'], box['Height'], extend_rate, ori_img.shape))\n",
    "                cropped_image, temp_bbox, size, boundary = crop_image(np_image, head_bbox, label)\n",
    "                head_result = []\n",
    "                head_result.append({'bbox': [0, 0, 255, 255]})\n",
    "                head_pred, _ = process_model(model_head, dataset_head, head_result, cropped_image)\n",
    "                head_pred = to_ori_cordinates(head_pred, temp_bbox, size, boundary)\n",
    "                head_pred_list.append(head_pred)\n",
    "                head_bbox_list.append(head_bbox)\n",
    "                # store data to list\n",
    "                pred_cur_idx = len(head_pred_list)-1\n",
    "                bbox_cur_idx = len(head_bbox_list)-1\n",
    "                save_data(pred_list, bbox_list, head_pred, pred_cur_idx, box, bbox_cur_idx, 'Head', frameId, customLabel['Confidence'])\n",
    "#                 img = vis_pose(head_pred, img, 'Head', frameId, data_list)\n",
    "            elif label == 'cow' or label == 'animal':\n",
    "                extend_rate = 0.05\n",
    "                np_image = np.array(ori_img)\n",
    "                cow_bbox = list(extend_bbox(box['Left'], box['Top'], box['Width'], box['Height'], extend_rate, ori_img.shape))\n",
    "                cropped_image, temp_bbox, size, boundary = crop_image(np_image, cow_bbox, label)\n",
    "                cow_result = []\n",
    "                cow_result.append({'bbox': [0, 0, 255, 255]})\n",
    "                # spine\n",
    "                spine_pred, _ = process_model(model_spine, dataset_spine, cow_result, cropped_image)\n",
    "                spine_pred = to_ori_cordinates(spine_pred, temp_bbox, size, boundary)\n",
    "                spine_pred_list.append(spine_pred)\n",
    "                spine_bbox_list.append(cow_bbox)\n",
    "                # store data to list\n",
    "                pred_cur_idx = len(spine_pred_list)-1\n",
    "                bbox_cur_idx = len(spine_bbox_list)-1\n",
    "                save_data(pred_list, bbox_list, spine_pred, pred_cur_idx, box, bbox_cur_idx, 'Spine', frameId, customLabel['Confidence'])\n",
    "#                 for i, pred in enumerate(spine_pred):\n",
    "#                     pred_list.append([frameId, 'Spine', pred_cur_idx, i, pred[0], pred[1], pred[2]])\n",
    "#                 bbox_list.append([frameId, 'Spine', bbox_cur_idx, \n",
    "#                                   cow_bbox[0], cow_bbox[1], cow_bbox[2], cow_bbox[3]])\n",
    "#                 img = vis_pose(spine_pred, img, 'Spine', frameId, data_list)\n",
    "                # leg back\n",
    "                legb_pred, _ = process_model(model_leg_back, dataset_leg_back, cow_result, cropped_image)\n",
    "                legb_pred = to_ori_cordinates(legb_pred, temp_bbox, size, boundary)\n",
    "                legb_pred_list.append(legb_pred)\n",
    "                legb_bbox_list.append(cow_bbox)\n",
    "                # store data to list\n",
    "                pred_cur_idx = len(legb_pred_list)-1\n",
    "                bbox_cur_idx = len(legb_bbox_list)-1\n",
    "                save_data(pred_list, bbox_list, legb_pred, pred_cur_idx, box, bbox_cur_idx, 'Leg_back', frameId, customLabel['Confidence'])\n",
    "#                 img = vis_pose(legb_pred, img, 'Leg_back', frameId, data_list)\n",
    "                # leg front\n",
    "                extend_rate = 0.1\n",
    "                np_image = np.array(ori_img)\n",
    "                cow_bbox = list(extend_bbox(box['Left'], box['Top'], box['Width'], box['Height'], extend_rate, ori_img.shape))\n",
    "                cropped_image, temp_bbox, size, boundary = crop_image(np_image, cow_bbox, label)\n",
    "                cow_result = []\n",
    "                cow_result.append({'bbox': [0, 0, 255, 255]})\n",
    "                legf_pred, _ = process_model(model_leg_front, dataset_leg_front, cow_result, cropped_image)\n",
    "                legf_pred = to_ori_cordinates(legf_pred, temp_bbox, size, boundary)\n",
    "                legf_pred_list.append(legf_pred)\n",
    "                legf_bbox_list.append(cow_bbox)\n",
    "                # store data to list\n",
    "                pred_cur_idx = len(legf_pred_list)-1\n",
    "                bbox_cur_idx = len(legf_bbox_list)-1\n",
    "                save_data(pred_list, bbox_list, legf_pred, pred_cur_idx, box, bbox_cur_idx, 'Leg_front', frameId, customLabel['Confidence'])\n",
    "#                 img = vis_pose(legf_pred, img, 'Leg_front', frameId, data_list)\n",
    "            elif label == 'tail':\n",
    "                extend_rate = 0.05\n",
    "                np_image = np.array(ori_img)\n",
    "                tail_bbox = list(extend_bbox(box['Left'], box['Top'], box['Width'], box['Height'], extend_rate, ori_img.shape))\n",
    "                cropped_image, temp_bbox, size, boundary = crop_image(np_image, tail_bbox, label)\n",
    "                tail_bound = size\n",
    "                tail_result = []\n",
    "                tail_result.append({'bbox': [0, 0, 255, 255]})\n",
    "                tail_pred, _ = process_model(model_tail, dataset_tail, tail_result, cropped_image)\n",
    "                tail_pred = to_ori_cordinates(tail_pred, temp_bbox, size, boundary)\n",
    "                tail_pred_list.append(tail_pred)\n",
    "                tail_bbox_list.append(tail_bbox)\n",
    "                # store data to list\n",
    "                pred_cur_idx = len(tail_pred_list)-1\n",
    "                bbox_cur_idx = len(tail_bbox_list)-1\n",
    "                save_data(pred_list, bbox_list, tail_pred, pred_cur_idx, box, bbox_cur_idx, 'Tail', frameId, customLabel['Confidence'])\n",
    "#                 img = vis_pose(tail_pred, img, 'Tail', frameId, data_list)\n",
    "#*****\n",
    "#     print(spine_pred_list)\n",
    "#     print()\n",
    "#     print(pred_list)\n",
    "#     print()\n",
    "#     print(spine_bbox_list)\n",
    "#     print()\n",
    "#     print(bbox_list)\n",
    "#     for i, spine_pred in enumerate(spine_pred_list):\n",
    "#         for pred in spine_pred:\n",
    "#             print(pred)\n",
    "#     for i, tail_pred in enumerate(tail_pred_list):\n",
    "#     for i, legf_pred in enumerate(legf_pred_list):\n",
    "#     for i, legb_pred in enumerate(legb_pred_list):\n",
    "#     for i, head_pred in enumerate(head_pred_list):\n",
    "\n",
    "#      # draw kp and lines in indiviual bbox\n",
    "#     for i, spine_pred in enumerate(spine_pred_list):\n",
    "#         # draw connection line with diff part\n",
    "#         img = draw_line_connect(spine_pred_list[i], legf_pred_list[i], 'Spine', 'Leg_front', img)\n",
    "#         img = draw_line_connect(spine_pred_list[i], legb_pred_list[i], 'Spine', 'Leg_back', img)\n",
    "#         # draw \n",
    "#         img = vis_pose(spine_pred, img, 'Spine', frameId, data_list)\n",
    "#     for i, tail_pred in enumerate(tail_pred_list):\n",
    "#         img = vis_pose(tail_pred, img, 'Tail', frameId, data_list)\n",
    "#     for i, legf_pred in enumerate(legf_pred_list):\n",
    "#         img = vis_pose(legf_pred, img, 'Leg_front', frameId, data_list)\n",
    "#     for i, legb_pred in enumerate(legb_pred_list):\n",
    "#         img = vis_pose(legb_pred, img, 'Leg_back', frameId, data_list)\n",
    "#     for i, head_pred in enumerate(head_pred_list):\n",
    "#         img = vis_pose(head_pred, img, 'Head', frameId, data_list)\n",
    "            \n",
    "#     # search cooresponding bbox for drawing on mutual bbox\n",
    "#     for i, spine_bbox in enumerate(spine_bbox_list):\n",
    "#         # find corresponding head bbox and get mutual angle\n",
    "#         for j, head_bbox in enumerate(head_bbox_list):\n",
    "#             ra = Rectangle(spine_bbox[0], spine_bbox[1], spine_bbox[0]+spine_bbox[2], spine_bbox[1]+spine_bbox[3])\n",
    "#             rb = Rectangle(head_bbox[0], head_bbox[1], head_bbox[0]+head_bbox[2], head_bbox[1]+head_bbox[3])\n",
    "#             overlap_area = get_overlap_area(ra, rb)\n",
    "#             head_area = head_bbox[2] * head_bbox[3]\n",
    "#             if overlap_area and head_area * 0.2 < overlap_area:\n",
    "#                 img = vis_mutual_angle(head_pred_list[j], spine_pred_list[i], 'Head', 'Spine', img, frameId, data_list)\n",
    "#                 break\n",
    "#         # find corresponding tail bbox and get mutual angle\n",
    "#         for j, tail_bbox in enumerate(tail_bbox_list):\n",
    "#             ra = Rectangle(spine_bbox[0], spine_bbox[1], spine_bbox[0]+spine_bbox[2], spine_bbox[1]+spine_bbox[3])\n",
    "#             rb = Rectangle(tail_bbox[0], tail_bbox[1], tail_bbox[0]+tail_bbox[2], tail_bbox[1]+tail_bbox[3])\n",
    "#             overlap_area = get_overlap_area(ra, rb)\n",
    "#             tail_area = tail_bbox[2] * tail_bbox[3]\n",
    "#             if overlap_area and tail_area * 0.2 < overlap_area:\n",
    "#                 img = vis_mutual_angle(tail_pred_list[j], spine_pred_list[i], 'Tail', 'Spine', img, frameId, data_list)\n",
    "#                 break\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "embedded-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzeVideo(src_video, src_bbox_json, src_img_dir, output_file, video, fps=5):\n",
    "    \n",
    "    start = time.time()\n",
    "    srcBGR = cv2.imread(src_img_dir+str(0)+'.jpg')\n",
    "    height, width, channels = srcBGR.shape\n",
    "    imgSize = (width, height)\n",
    "    cap = cv2.VideoCapture(src_video)\n",
    "    frameRate = cap.get(fps) #frame rate\n",
    "    print('FrameRate:', frameRate)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    videoWriter = cv2.VideoWriter(output_file, fourcc, frameRate, imgSize) \n",
    "    \n",
    "    with open(src_bbox_json) as bbox_json:\n",
    "        bbox_frames = json.load(bbox_json)\n",
    "        data_list = []\n",
    "        pred_list = []\n",
    "        bbox_list = []\n",
    "        for frameId, bbox_data in enumerate(bbox_frames['Frames']):\n",
    "            # skip frame 350, 450, 550, 650, 750, 850, 950\n",
    "            #550, 850 opposite\n",
    "            frame_list = [550]\n",
    "            checking = False\n",
    "            if checking and frameId not in frame_list:\n",
    "                continue\n",
    "            # get each image frame\n",
    "            srcBGR = cv2.imread(src_img_dir+str(frameId)+'.jpg')\n",
    "            img = cv2.cvtColor(srcBGR, cv2.COLOR_BGR2RGB)\n",
    "            inferred_frame = draw_response(img, bbox_data, 'cow', frameId, data_list, pred_list, bbox_list)\n",
    "#             # uncommet this part for testing\n",
    "            if checking and (frameId in frame_list):\n",
    "                temp_frame = cv2.cvtColor(inferred_frame, cv2.COLOR_BGR2RGB)\n",
    "                temp_image = Image.fromarray(temp_frame)\n",
    "                temp_image.save('./'+'check_trail_'+str(frameId)+'_image.jpg')\n",
    "            # check each 50 frame\n",
    "            if frameId % 50 == 0:\n",
    "                print(\"Finish Processing {} frame\".format(frameId))\n",
    "                plt.title(\"Frame {}\".format(int(frameId)))\n",
    "                plt.savefig('debug_imgs/check_{}.jpg'.format(frameId), dpi=200)\n",
    "                lap = time.time()\n",
    "                print('lap time: ', lap - start)\n",
    "            videoWriter.write(inferred_frame)\n",
    "        df = pd.DataFrame.from_records(data_list, columns=['frameId', 'keypoint_type', 'kp_x', 'kp_y', 'angle'])\n",
    "        print(df.info(verbose=True))\n",
    "        kp_df = pd.DataFrame.from_records(pred_list, columns=['frameId', 'label', 'bbox_idx', 'kp_idx', 'x', 'y', 'conf'])\n",
    "        print(kp_df.info(verbose=True))\n",
    "        bbox_df = pd.DataFrame.from_records(bbox_list, columns=['frameId', 'label', 'bbox_idx', \n",
    "                                                        'top_left_x', 'top_left_y', 'width', 'height', 'conf'])\n",
    "        print(bbox_df.info(verbose=True))\n",
    "#         print(bbox_df)\n",
    "        kp_df.to_csv('csv_data/'+video+'_kp.csv',index=False)\n",
    "        bbox_df.to_csv('csv_data/'+video+'_bbox.csv',index=False)\n",
    "#         df.to_csv('csv_data/'+video+'_angle.csv',index=False)\n",
    "    videoWriter.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    bbox_json.close()\n",
    "    \n",
    "    #end time\n",
    "    end = time.time()\n",
    "    print('total time lapse', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "strange-algebra",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_data/inferred_video/inferred_v3_cattle_multi_1.mp4\n",
      "FrameRate: 30.006466910972193\n",
      "Finish Processing 0 frame\n",
      "lap time:  1.659081220626831\n",
      "Finish Processing 50 frame\n",
      "lap time:  50.633328914642334\n",
      "Finish Processing 100 frame\n",
      "lap time:  104.38447761535645\n",
      "Finish Processing 150 frame\n",
      "lap time:  152.61625623703003\n",
      "Finish Processing 200 frame\n",
      "lap time:  200.45087790489197\n",
      "Finish Processing 250 frame\n",
      "lap time:  249.70553612709045\n",
      "Finish Processing 300 frame\n",
      "lap time:  307.3155417442322\n",
      "Finish Processing 350 frame\n",
      "lap time:  361.18591022491455\n",
      "Finish Processing 400 frame\n",
      "lap time:  410.1520686149597\n",
      "Finish Processing 450 frame\n",
      "lap time:  468.2195131778717\n",
      "Finish Processing 500 frame\n",
      "lap time:  532.621080160141\n",
      "Finish Processing 550 frame\n",
      "lap time:  595.8801877498627\n",
      "Finish Processing 600 frame\n",
      "lap time:  646.1605124473572\n",
      "Finish Processing 650 frame\n",
      "lap time:  683.5816085338593\n",
      "Finish Processing 700 frame\n",
      "lap time:  725.1672384738922\n",
      "Finish Processing 750 frame\n",
      "lap time:  771.8210167884827\n",
      "Finish Processing 800 frame\n",
      "lap time:  830.5103933811188\n",
      "Finish Processing 850 frame\n",
      "lap time:  887.1392652988434\n",
      "Finish Processing 900 frame\n",
      "lap time:  949.8679602146149\n",
      "Finish Processing 950 frame\n",
      "lap time:  992.2394232749939\n",
      "Finish Processing 1000 frame\n",
      "lap time:  1022.6522347927094\n",
      "Finish Processing 1050 frame\n",
      "lap time:  1075.8739697933197\n",
      "Finish Processing 1100 frame\n",
      "lap time:  1155.784918308258\n",
      "Finish Processing 1150 frame\n",
      "lap time:  1235.9083738327026\n",
      "Finish Processing 1200 frame\n",
      "lap time:  1306.827630519867\n",
      "Finish Processing 1250 frame\n",
      "lap time:  1385.7028625011444\n",
      "Finish Processing 1300 frame\n",
      "lap time:  1449.32093667984\n",
      "Finish Processing 1350 frame\n",
      "lap time:  1506.7552857398987\n",
      "Finish Processing 1400 frame\n",
      "lap time:  1591.244888305664\n",
      "Finish Processing 1450 frame\n",
      "lap time:  1672.9617581367493\n",
      "Finish Processing 1500 frame\n",
      "lap time:  1745.0225102901459\n",
      "Finish Processing 1550 frame\n",
      "lap time:  1816.93696641922\n",
      "Finish Processing 1600 frame\n",
      "lap time:  1877.1870160102844\n",
      "Finish Processing 1650 frame\n",
      "lap time:  1940.198231935501\n",
      "Finish Processing 1700 frame\n",
      "lap time:  1996.0075693130493\n",
      "Finish Processing 1750 frame\n",
      "lap time:  2084.1143469810486\n",
      "Finish Processing 1800 frame\n",
      "lap time:  2182.6795530319214\n",
      "Finish Processing 1850 frame\n",
      "lap time:  2259.8283455371857\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   frameId        0 non-null      object\n",
      " 1   keypoint_type  0 non-null      object\n",
      " 2   kp_x           0 non-null      object\n",
      " 3   kp_y           0 non-null      object\n",
      " 4   angle          0 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 0.0+ bytes\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 378207 entries, 0 to 378206\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   frameId   378207 non-null  int64  \n",
      " 1   label     378207 non-null  object \n",
      " 2   bbox_idx  378207 non-null  int64  \n",
      " 3   kp_idx    378207 non-null  int64  \n",
      " 4   x         378207 non-null  float64\n",
      " 5   y         378207 non-null  float64\n",
      " 6   conf      378207 non-null  float64\n",
      "dtypes: float64(3), int64(3), object(1)\n",
      "memory usage: 20.2+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19963 entries, 0 to 19962\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   frameId     19963 non-null  int64  \n",
      " 1   label       19963 non-null  object \n",
      " 2   bbox_idx    19963 non-null  int64  \n",
      " 3   top_left_x  19963 non-null  float64\n",
      " 4   top_left_y  19963 non-null  float64\n",
      " 5   width       19963 non-null  float64\n",
      " 6   height      19963 non-null  float64\n",
      " 7   conf        19963 non-null  float64\n",
      "dtypes: float64(5), int64(2), object(1)\n",
      "memory usage: 1.2+ MB\n",
      "None\n",
      "total time lapse 2270.4961092472076\n",
      "finished analyzing the video cattle_multi_1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# main function\n",
    "video_name_list = ['cattle_multi_1']\n",
    "video_format = ['.mov']\n",
    "for v_idx, video in enumerate(video_name_list):\n",
    "    src_video = 'video_data/input_video/'+video+video_format[v_idx]\n",
    "    src_bbox_json = 'json_data_v3/'+video+'_new_bbox.json'\n",
    "    src_img_dir = 'frame_img/'+video+'/'\n",
    "    output_video = 'video_data/inferred_video/inferred_v3_'+video+'.mp4'\n",
    "    print(output_video)\n",
    "    analyzeVideo(src_video, src_bbox_json, src_img_dir, output_video, video)\n",
    "    print('finished analyzing the video '+video)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "invisible-creation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%HTML\n",
    "# <video width=\"720\" height=\"640\" controls>\n",
    "#   <source src='./video_data/inferred_video/inferred_v3_IMG_4195.mp4', type=\"video/mp4\">\n",
    "# </video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-september",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p36] *",
   "language": "python",
   "name": "conda-env-pytorch_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
