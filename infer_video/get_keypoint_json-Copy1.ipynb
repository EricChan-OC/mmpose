{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "young-potter",
   "metadata": {},
   "source": [
    "## Import all Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "satellite-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS Rekognition to get bbox\n",
    "import numpy as np\n",
    "import boto3\n",
    "from PIL import Image, ImageDraw, ExifTags, ImageColor, ImageFont\n",
    "from matplotlib import pyplot as plt\n",
    "from utils.rekognition import determine_color, draw_animal_count\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "from utils.config import *\n",
    "from utils.fix_annotation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "employed-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process whole image.py to get key points\n",
    "import mmcv\n",
    "from mmcv.parallel import collate, scatter\n",
    "from mmcv.runner import load_checkpoint\n",
    "import torch as tr\n",
    "#from torchvision import transforms\n",
    "from mmpose.apis import (inference, inference_top_down_pose_model, init_pose_model,\n",
    "                         vis_pose_result)\n",
    "from mmpose.models import build_posenet\n",
    "from mmpose.datasets.pipelines import Compose\n",
    "\n",
    "FNT = ImageFont.truetype('/usr/share/fonts/default/Type1/n019004l.pfb', 23)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-marble",
   "metadata": {},
   "source": [
    "## Get Bounding Boxes from Video Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "union-lloyd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadImage:\n",
    "    \"\"\"A simple pipeline to load image.\"\"\"\n",
    "\n",
    "    def __init__(self, color_type='color', channel_order='rgb'):\n",
    "        self.color_type = color_type\n",
    "        self.channel_order = channel_order\n",
    "\n",
    "    def __call__(self, results):\n",
    "        \"\"\"Call function to load images into results.\n",
    "        Args:\n",
    "            results (dict): A result dict contains the img_or_path.\n",
    "        Returns:\n",
    "            dict: ``results`` will be returned containing loaded image.\n",
    "        \"\"\"\n",
    "        if isinstance(results['img_or_path'], str):\n",
    "            results['image_file'] = results['img_or_path']\n",
    "            img = mmcv.imread(results['img_or_path'], self.color_type,\n",
    "                              self.channel_order)\n",
    "        elif isinstance(results['img_or_path'], np.ndarray):\n",
    "            results['image_file'] = ''\n",
    "            if self.color_type == 'color' and self.channel_order == 'rgb':\n",
    "                img = cv2.cvtColor(results['img_or_path'], cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            raise TypeError('\"img_or_path\" must be a numpy array or a str or '\n",
    "                            'a pathlib.Path object')\n",
    "        results['img'] = img\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "important-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_pose_model(config, checkpoint=None, device='cuda:0'):\n",
    "    \"\"\"Initialize a pose model from config file.\n",
    "    Args:\n",
    "        config (str or :obj:`mmcv.Config`): Config file path or the config\n",
    "            object.\n",
    "        checkpoint (str, optional): Checkpoint path. If left as None, the model\n",
    "            will not load any weights.\n",
    "    Returns:\n",
    "        nn.Module: The constructed detector.\n",
    "    \"\"\"\n",
    "    if isinstance(config, str):\n",
    "        config = mmcv.Config.fromfile(config)\n",
    "    elif not isinstance(config, mmcv.Config):\n",
    "        raise TypeError('config must be a filename or Config object, '\n",
    "                        f'but got {type(config)}')\n",
    "    config.model.pretrained = None\n",
    "    model = build_posenet(config.model)\n",
    "    if checkpoint is not None:\n",
    "        # load model checkpoint\n",
    "        load_checkpoint(model, checkpoint, map_location=device)\n",
    "    # save the config in the model for convenience\n",
    "    model.cfg = config\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "administrative-philip",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _box2cs(cfg, box):\n",
    "    \"\"\"This encodes bbox(x,y,w,h) into (center, scale)\n",
    "    Args:\n",
    "        x, y, w, h\n",
    "    Returns:\n",
    "        tuple: A tuple containing center and scale.\n",
    "        - np.ndarray[float32](2,): Center of the bbox (x, y).\n",
    "        - np.ndarray[float32](2,): Scale of the bbox w & h.\n",
    "    \"\"\"\n",
    "\n",
    "    x, y, w, h = box[:4]\n",
    "    input_size = cfg.data_cfg['image_size']\n",
    "    aspect_ratio = input_size[0] / input_size[1]\n",
    "    center = np.array([x + w * 0.5, y + h * 0.5], dtype=np.float32)\n",
    "\n",
    "    if w > aspect_ratio * h:\n",
    "        h = w * 1.0 / aspect_ratio\n",
    "    elif w < aspect_ratio * h:\n",
    "        w = h * aspect_ratio\n",
    "\n",
    "    # pixel std is 200.0\n",
    "    scale = np.array([w / 200.0, h / 200.0], dtype=np.float32)\n",
    "\n",
    "    scale = scale * 1.25\n",
    "\n",
    "    return center, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sized-hebrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_model(model, dataset, person_results, img_or_path):\n",
    "    bboxes = np.array([box['bbox'] for box in person_results])\n",
    "    cfg = model.cfg\n",
    "    flip_pairs = None\n",
    "    device = next(model.parameters()).device\n",
    "    channel_order = cfg.test_pipeline[0].get('channel_order', 'rgb')\n",
    "    test_pipeline = [LoadImage(channel_order=channel_order)] + cfg.test_pipeline[1:]\n",
    "    test_pipeline = Compose(test_pipeline)\n",
    "    if dataset == 'AnimalHorse10Dataset':\n",
    "        flip_pairs = []\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "    batch_data = []\n",
    "    for bbox in bboxes:\n",
    "        center, scale = _box2cs(cfg, bbox)\n",
    "        # prepare data\n",
    "        data = {\n",
    "            'img_or_path':\n",
    "            img_or_path,\n",
    "            'center':\n",
    "            center,\n",
    "            'scale':\n",
    "            scale,\n",
    "            'bbox_score':\n",
    "            bbox[4] if len(bbox) == 5 else 1,\n",
    "            'bbox_id':\n",
    "            0,  # need to be assigned if batch_size > 1\n",
    "            'dataset':\n",
    "            dataset,\n",
    "            'joints_3d':\n",
    "            np.zeros((cfg.data_cfg.num_joints, 3), dtype=np.float32),\n",
    "            'joints_3d_visible':\n",
    "            np.zeros((cfg.data_cfg.num_joints, 3), dtype=np.float32),\n",
    "            'rotation':\n",
    "            0,\n",
    "            'ann_info': {\n",
    "                'image_size': np.array(cfg.data_cfg['image_size']),\n",
    "                'num_joints': cfg.data_cfg['num_joints'],\n",
    "                'flip_pairs': flip_pairs\n",
    "            }\n",
    "        }\n",
    "        data = test_pipeline(data)\n",
    "        batch_data.append(data)\n",
    "    batch_data = collate(batch_data, samples_per_gpu=1)\n",
    "    if next(model.parameters()).is_cuda:\n",
    "        # scatter not work so just move image to cuda device\n",
    "        batch_data['img'] = batch_data['img'].to(device)\n",
    "    # get all img_metas of each bounding box\n",
    "    batch_data['img_metas'] = [\n",
    "        img_metas[0] for img_metas in batch_data['img_metas'].data\n",
    "    ]\n",
    "\n",
    "    with tr.no_grad():\n",
    "        result = model(\n",
    "            img=batch_data['img'],\n",
    "            #img = torch_data,\n",
    "            img_metas=batch_data['img_metas'],\n",
    "            return_loss=False,\n",
    "            return_heatmap=False)\n",
    "    return result['preds'], result['output_heatmap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "periodic-community",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use load_from_local loader\n",
      "Use load_from_local loader\n",
      "Use load_from_local loader\n",
      "Use load_from_local loader\n",
      "Use load_from_local loader\n"
     ]
    }
   ],
   "source": [
    "device = tr.device(\"cuda:0\" if tr.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model_head = init_pose_model(config='../myConfigs/train_head_resnet.py', checkpoint='../temp_logs/cattle_head/resnet/best.pth', device = device)\n",
    "model_spine = init_pose_model(config='../myConfigs/train_spine_hrnet.py', checkpoint='../temp_logs/cattle_spine/hrnet/best.pth', device = device)\n",
    "model_tail = init_pose_model(config='../myConfigs/train_tail_ori_hrnet.py', checkpoint='../temp_logs/cattle_tail_ori/hrnet/best.pth', device = device)\n",
    "model_leg_front = init_pose_model(config='../myConfigs/train_leg_front_hrnet.py', checkpoint='../temp_logs/cattle_leg_front/hrnet/best.pth', device = device)\n",
    "model_leg_back = init_pose_model(config='../myConfigs/train_leg_back_hrnet.py', checkpoint='../temp_logs/cattle_leg_back/hrnet/best.pth', device = device)\n",
    "\n",
    "dataset_head = model_head.cfg.data['test']['type']\n",
    "dataset_spine = model_spine.cfg.data['test']['type']\n",
    "dataset_tail = model_tail.cfg.data['test']['type']\n",
    "dataset_leg_front = model_leg_front.cfg.data['test']['type']\n",
    "dataset_leg_back = model_leg_back.cfg.data['test']['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "printable-geology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kp_color(label):\n",
    "    # BGR\n",
    "    color = (0, 0, 255)\n",
    "    if label == 'Head':\n",
    "        color = ['#EC51F8', '#74F54B', \n",
    "                 '#EC51F8', '#74F54B',\n",
    "                 '#4394F9', '#F49736',\n",
    "                 '#F49736', '#FFFB56',\n",
    "                 '#FFFB56', '#4394F9',\n",
    "                 '#07178D']\n",
    "    elif label == 'Spine':\n",
    "          color = ['#4394F9', '#4394F9', '#4394F9',\n",
    "                  '#4394F9', '#4394F9', '#4394F9', \n",
    "                  '#4394F9', '#4394F9', '#24518D']\n",
    "    elif label == 'Tail':\n",
    "        color = ['#EC51F8', '#EC51F8',\n",
    "                '#EC51F8', '#EC51F8',\n",
    "                '#EC51F8', '#892B8E']\n",
    "    elif label == 'Leg_front':\n",
    "        color = ['#F49736', '#F49736',\n",
    "                '#F49736', '#F49736',\n",
    "                '#F49736', '#F49736',\n",
    "                '#F49736', '#F49736',\n",
    "                '#F49736', '#8C551E']\n",
    "    elif label == 'Leg_back':\n",
    "        color = ['#74F54B', '#74F54B',\n",
    "                '#74F54B', '#74F54B',\n",
    "                '#74F54B', '#74F54B',\n",
    "                '#74F54B', '#74F54B',\n",
    "                '#74F54B', '#3F8D28',]\n",
    "    return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "grand-impossible",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skeleton(label):\n",
    "    skeleton_list = []\n",
    "    if label == 'Head':\n",
    "        skeleton_list = [[4, 0], [4, 2], [0, 2], [1, 3], \n",
    "                        [5, 6], [7, 8], [0, 1], [1, 5],\n",
    "                        [5, 7], [7, 9], [2, 3], [3, 6],\n",
    "                        [6, 8], [8, 9], [4, 9]]\n",
    "    elif label == 'Spine':\n",
    "        skeleton_list = [[0, 1], [1, 2], [2, 3], [3, 4],\n",
    "                        [4, 5], [5, 6], [6, 7]]\n",
    "    elif label == 'Tail':\n",
    "        skeleton_list = [[0, 1], [1, 2], [2, 3], [3, 4]]\n",
    "    elif label == 'Leg_front':\n",
    "        skeleton_list = [[0, 1], [1, 2], [2, 3], [3, 4],\n",
    "                        [4, 5], [5, 6], [6, 7], [7, 8]]\n",
    "    elif label == 'Leg_back':\n",
    "        skeleton_list = [[0, 1], [1, 2], [2, 3], [3, 4],\n",
    "                        [4, 5], [5, 6], [6, 7], [7, 8]]\n",
    "    return skeleton_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "underlying-paper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_bgr(color):\n",
    "    color = list(color)\n",
    "    temp_r = color[0]\n",
    "    color[0] = color[2]\n",
    "    color[2] = temp_r\n",
    "    return tuple(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "minimal-holmes",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_pose(points, draw, label):\n",
    "    points = points[0]\n",
    "#     if label == 'Tail' or label == 'Leg_front' or label == 'Leg_back':\n",
    "#         print(label)\n",
    "#         print(points)\n",
    "#     if label == 'Leg_front' or label == 'Leg_back':\n",
    "#         return draw\n",
    "    CS_THR = 0.4\n",
    "    # keypoints\n",
    "    kp_color = get_kp_color(label)\n",
    "    # connect line\n",
    "    skeleton_list = get_skeleton(label)\n",
    "    for ske in skeleton_list:\n",
    "        #print(points)\n",
    "        fir_pt_x, fir_pt_y, fir_pt_p = points[ske[0]]\n",
    "        sec_pt_x, sec_pt_y, sec_pt_p = points[ske[1]]\n",
    "        if fir_pt_p > CS_THR and sec_pt_p > CS_THR:\n",
    "            shape = [(fir_pt_x, fir_pt_y), (sec_pt_x, sec_pt_y)]\n",
    "            draw.line(shape, fill=kp_color[-1], width=8)\n",
    "    for i, point in enumerate(points):\n",
    "        x, y, p = point\n",
    "        if p > CS_THR:\n",
    "            x = int(x)\n",
    "            y = int(y)\n",
    "            draw.ellipse([(x-11, y-11), (x+11, y+11)], fill=kp_color[-1], outline=None)\n",
    "            draw.ellipse([(x-6, y-6), (x+6, y+6)], fill=kp_color[i], outline=None)\n",
    "            #draw.text((x-40, y-40), '{}%'.format(int(p*100)), font=FNT, fill=(255, 255, 255))\n",
    "    return draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "thick-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_bbox(left, top, width, height, extend_rate):\n",
    "    temp_left = left - left * extend_rate\n",
    "    temp_top = top - top * extend_rate\n",
    "    temp_width = width * extend_rate + width\n",
    "    temp_height = height * extend_rate + height\n",
    "    return temp_left, temp_top, temp_width, temp_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "still-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color(name):\n",
    "    \n",
    "    if name == 'Cow':\n",
    "        color = '#FF9300'\n",
    "    elif name == 'Head' or name == \"Head Left\" or name == \"Head Right\":\n",
    "        color = '#0096FF'\n",
    "    elif name == 'Tag':\n",
    "        color = '#00FFFF'\n",
    "    elif name == 'Knee':\n",
    "        color = '#FFFB00'\n",
    "    elif name == 'Hoof':\n",
    "        color = '#00F900'\n",
    "    elif name == 'Tail':\n",
    "        color = '#FF40FF'\n",
    "    elif name == 'Side Left' or name == 'Side Right':\n",
    "        color = '#FF2600'\n",
    "    elif name == 'Udder':\n",
    "        color = '#9437FF'\n",
    "    elif name == 'Teat':\n",
    "        color = '#FF2F92'\n",
    "    else:\n",
    "        color = '#000000'\n",
    "\n",
    "    return color\n",
    "\n",
    "def get_opacity(name):\n",
    "    \n",
    "    if name == 'Cow':\n",
    "        opacity = 0.3\n",
    "    elif name == 'Tag':\n",
    "        opacity = 0.3\n",
    "    elif name == 'Head' or name == \"Head Left\" or name == \"Head Right\":\n",
    "        opacity = 0.45\n",
    "    elif name == 'Knee':\n",
    "        opacity = 0.3\n",
    "    elif name == 'Hoof':\n",
    "        opacity = 0.35\n",
    "    elif name == 'Tail':\n",
    "        opacity = 0.3\n",
    "    elif name == 'Side Left' or name == 'Side Right':\n",
    "        opacity = 0.3\n",
    "    elif name == 'Udder':\n",
    "        opacity = 0.35\n",
    "    elif name == 'Teat':\n",
    "        opacity = 0.3\n",
    "    else:\n",
    "        opacity = 0.0\n",
    "\n",
    "    return opacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "celtic-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confidence_cut_off(name):\n",
    "\n",
    "    if name == 'Cow':\n",
    "        confidence = 79.4\n",
    "    elif name == 'Tag':\n",
    "        confidence = 86.9\n",
    "    elif name == 'Head':\n",
    "        confidence = 92.5\n",
    "    elif name == 'Knee':\n",
    "        confidence = 78.0\n",
    "    elif name == 'Hoof':\n",
    "        confidence = 92.9\n",
    "    elif name == 'Tail':\n",
    "        confidence = 73.5\n",
    "    elif name == 'Udder':\n",
    "        confidence = 35.0\n",
    "    elif name == 'Teat':\n",
    "        confidence = 73.0\n",
    "    else:\n",
    "        confidence = 80.0\n",
    "\n",
    "    return confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "trained-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "tail_count = 0\n",
    "#draw response\n",
    "def draw_response(image, response, animal_target, draw_boundary=True, fill=True, draw_btn=True):\n",
    "    global tail_count\n",
    "    tail_check = False\n",
    "    temp_image = image.copy()\n",
    "    b, g, r = image.split()\n",
    "    image = Image.merge(\"RGB\", (r, g, b))\n",
    "    # original image size\n",
    "    draw = ImageDraw.Draw(image, mode='RGBA')\n",
    "    # bbox\n",
    "    for customLabel in response['CustomLabels']:\n",
    "        if 'Geometry' in customLabel:\n",
    "            box = customLabel['Geometry']['BoundingBox']\n",
    "\n",
    "            left, top, width, height = extend_bbox(box['Left'], box['Top'], box['Width'], box['Height'], 0)\n",
    "            label = customLabel['Name']\n",
    "            if label == 'Udder':\n",
    "                print('Udder')\n",
    "            elif label == 'Teat':\n",
    "                print('Teat')\n",
    "            conf_cut = get_confidence_cut_off(label)\n",
    "            # skip current label\n",
    "            if customLabel['Confidence'] < conf_cut:\n",
    "                continue\n",
    "            #draw bbox\n",
    "            color = get_color(label)\n",
    "            opacity = round(get_opacity(label) * 255)\n",
    "            if draw_boundary and fill:  \n",
    "                draw.rectangle(xy=[(left, top), (left+width, top+height)], outline=color, fill=color+f'{opacity:0>2X}', width=3)\n",
    "            elif fill:\n",
    "                draw.rectangle(xy=[(left, top), (left+width, top+height)], outline=None, fill=color+f'{opacity:0>2X}', width=3)\n",
    "            elif draw_boundary:\n",
    "                draw.rectangle(xy=[(left, top), (left+width, top+height)], outline=color, fill=None, width=3)\n",
    "            if draw_btn:\n",
    "                text_width, text_height = FNT.getsize(label)\n",
    "                draw.rectangle(xy=[(left, top), (left+text_width, top+text_height)], outline=None, fill=color, width=3)\n",
    "                draw.text((left, top), label, fill='#000000', font=FNT)\n",
    "    #keypoints\n",
    "    for customLabel in response['CustomLabels']:\n",
    "        if 'Geometry' in customLabel:\n",
    "            box = customLabel['Geometry']['BoundingBox']\n",
    "            left, top, width, height = extend_bbox(box['Left'], box['Top'], box['Width'], box['Height'], 0)\n",
    "            label = customLabel['Name']\n",
    "            conf_cut = get_confidence_cut_off(label)\n",
    "            # skip current label\n",
    "            if customLabel['Confidence'] < conf_cut:\n",
    "                continue\n",
    "        #***** Keypoints\n",
    "            if label == 'Head':\n",
    "                extend_rate = 0.01\n",
    "                np_image = np.array(temp_image)                \n",
    "                head_bbox = list(extend_bbox(box['Left'], box['Top'], box['Width'], box['Height'], extend_rate))\n",
    "                head_result = []\n",
    "                head_result.append({'bbox': head_bbox})\n",
    "                preds, _ = process_model(model_head, dataset_head, head_result, np_image)\n",
    "\n",
    "                draw = vis_pose(preds, draw, 'Head')\n",
    "            elif label == 'Cow':\n",
    "                extend_rate = 0.01\n",
    "                np_image = np.array(temp_image)\n",
    "                cow_bbox = list(extend_bbox(box['Left'], box['Top'], box['Width'], box['Height'], extend_rate))\n",
    "                cow_result = []\n",
    "                cow_result.append({'bbox': cow_bbox})\n",
    "                # spine\n",
    "                preds, _ = process_model(model_spine, dataset_spine, cow_result, np_image)\n",
    "                draw = vis_pose(preds, draw, 'Spine')\n",
    "                # leg front\n",
    "                preds, _ = process_model(model_leg_front, dataset_leg_front, cow_result, np_image)\n",
    "                draw = vis_pose(preds, draw, 'Leg_front')\n",
    "                # leg back\n",
    "                preds, _ = process_model(model_leg_back, dataset_leg_back, cow_result, np_image)\n",
    "                draw = vis_pose(preds, draw, 'Leg_back')\n",
    "            elif label == 'Tail':\n",
    "                extend_rate = 0.20\n",
    "                np_image = np.array(temp_image)\n",
    "                tail_bbox = list(extend_bbox(box['Left'], box['Top'], box['Width'], box['Height'], extend_rate))\n",
    "                tail_result = []\n",
    "                tail_result.append({'bbox': tail_bbox})\n",
    "                preds, _ = process_model(model_tail, dataset_tail, tail_result, np_image)\n",
    "                draw = vis_pose(preds, draw, 'Tail')\n",
    "                tail_check = True\n",
    "#*****\n",
    "    \n",
    "\n",
    "    img = np.asarray(image)[:,:,::-1].copy()\n",
    "    inferred_frame = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return inferred_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "embedded-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzeVideo(src_video, src_bbox_json, src_img_dir, output_file, fps=5):\n",
    "    \n",
    "    start = time.time()\n",
    "        #imgWidth, imgHeight = image.size\n",
    "    with Image.open(src_img_dir+'0.jpg') as img:\n",
    "        imgWidth, imgHeight = img.size\n",
    "        imgSize = (imgWidth, imgHeight)\n",
    "        img.close()\n",
    "    cap = cv2.VideoCapture(src_video)\n",
    "    frameRate = cap.get(fps) #frame rate\n",
    "    print('FrameRate:', frameRate)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    videoWriter = cv2.VideoWriter(output_file, fourcc, frameRate, imgSize) \n",
    "    \n",
    "    with open(src_bbox_json) as bbox_json:\n",
    "        bbox_frames = json.load(bbox_json)\n",
    "        for frameId, bbox_data in enumerate(bbox_frames['Frames']):\n",
    "            # get each image frame\n",
    "            with Image.open(src_img_dir+str(frameId)+'.jpg') as img:\n",
    "                inferred_frame = draw_response(img, bbox_data, animal_target='cow')\n",
    "                inferred_frame = cv2.cvtColor(inferred_frame, cv2.COLOR_BGR2RGB)\n",
    "                # check each 50 frame\n",
    "                if frameId % 50 == 0:\n",
    "                    print(\"Finish Processing {} frame\".format(frameId))\n",
    "                    plt.imshow(inferred_frame)\n",
    "                    plt.title(\"Frame {}\".format(int(frameId)))\n",
    "                    plt.savefig('debug_imgs/check_{}.jpg'.format(frameId), dpi=200)\n",
    "                    lap = time.time()\n",
    "                    print('lap time: ', lap - start)\n",
    "                videoWriter.write(inferred_frame)\n",
    "                img.close()\n",
    "\n",
    "    videoWriter.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    bbox_json.close()\n",
    "    \n",
    "    #end time\n",
    "    end = time.time()\n",
    "    print('total time lapse', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "strange-algebra",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_data/inferred_video/inferred_fixed_cattle_multi_1.mp4\n",
      "FrameRate: 30.006466910972193\n",
      "Finish Processing 0 frame\n",
      "lap time:  3.503347635269165\n",
      "Finish Processing 50 frame\n",
      "lap time:  109.85330510139465\n",
      "Finish Processing 100 frame\n",
      "lap time:  226.45562505722046\n",
      "Finish Processing 150 frame\n",
      "lap time:  333.6754539012909\n",
      "Finish Processing 200 frame\n",
      "lap time:  435.8921248912811\n",
      "Finish Processing 250 frame\n",
      "lap time:  540.8767602443695\n",
      "Finish Processing 300 frame\n",
      "lap time:  666.1351451873779\n",
      "Finish Processing 350 frame\n",
      "lap time:  785.4227914810181\n",
      "Finish Processing 400 frame\n",
      "lap time:  889.8876004219055\n",
      "Finish Processing 450 frame\n",
      "lap time:  1017.3974685668945\n",
      "Finish Processing 500 frame\n",
      "lap time:  1160.2743360996246\n",
      "Finish Processing 550 frame\n",
      "lap time:  1297.996387720108\n",
      "Finish Processing 600 frame\n",
      "lap time:  1404.5304102897644\n",
      "Finish Processing 650 frame\n",
      "lap time:  1485.1052141189575\n",
      "Finish Processing 700 frame\n",
      "lap time:  1569.8113861083984\n",
      "Finish Processing 750 frame\n",
      "lap time:  1669.618066072464\n",
      "Finish Processing 800 frame\n",
      "lap time:  1800.6987073421478\n",
      "Finish Processing 850 frame\n",
      "lap time:  1930.0983774662018\n",
      "Finish Processing 900 frame\n",
      "lap time:  2078.31814289093\n",
      "Finish Processing 950 frame\n",
      "lap time:  2175.210619211197\n",
      "Finish Processing 1000 frame\n",
      "lap time:  2239.294077396393\n",
      "Finish Processing 1050 frame\n",
      "lap time:  2356.8199532032013\n",
      "Finish Processing 1100 frame\n",
      "lap time:  2534.4868001937866\n",
      "Finish Processing 1150 frame\n",
      "lap time:  2717.6881663799286\n",
      "Finish Processing 1200 frame\n",
      "lap time:  2875.3263347148895\n",
      "Finish Processing 1250 frame\n",
      "lap time:  3054.7248158454895\n",
      "Finish Processing 1300 frame\n",
      "lap time:  3200.637379169464\n",
      "Finish Processing 1350 frame\n",
      "lap time:  3325.262978076935\n",
      "Finish Processing 1400 frame\n",
      "lap time:  3514.033369779587\n",
      "Finish Processing 1450 frame\n",
      "lap time:  3701.9489555358887\n",
      "Finish Processing 1500 frame\n",
      "lap time:  3859.1659972667694\n",
      "Finish Processing 1550 frame\n",
      "lap time:  4017.1473603248596\n",
      "Udder\n",
      "Finish Processing 1600 frame\n",
      "lap time:  4154.535991430283\n",
      "Finish Processing 1650 frame\n",
      "lap time:  4294.26210641861\n",
      "Finish Processing 1700 frame\n",
      "lap time:  4415.1077399253845\n",
      "Finish Processing 1750 frame\n",
      "lap time:  4619.905319452286\n",
      "Finish Processing 1800 frame\n",
      "lap time:  4859.329822778702\n",
      "Finish Processing 1850 frame\n",
      "lap time:  5039.599325895309\n",
      "total time lapse 5055.3730454444885\n",
      "finished analyzing the video cattle_multi_1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#, 'cattle_multi_1'\n",
    "video_name_list = ['cattle_multi_1']\n",
    "video_format = ['.mov']\n",
    "for v_idx, video in enumerate(video_name_list):\n",
    "    src_video = 'video_data/input_video/'+video+video_format[v_idx]\n",
    "    src_bbox_json = 'json_data/'+video+'_new_bbox.json'\n",
    "    src_img_dir = 'frame_img/'+video+'/'\n",
    "    output_video = 'video_data/inferred_video/inferred_fixed_'+video+'.mp4'\n",
    "    print(output_video)\n",
    "    analyzeVideo(src_video, src_bbox_json, src_img_dir, output_video)\n",
    "    print('finished analyzing the video '+video)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-grade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p36] *",
   "language": "python",
   "name": "conda-env-pytorch_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
